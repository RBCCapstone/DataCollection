{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.stats as stats\n",
    "import sklearn\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report \n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances, manhattan_distances, euclidean_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# we'll compare two stemmers and a lemmatizer\n",
    "#lrStem = LancasterStemmer()\n",
    "#sbStem = SnowballStemmer(\"english\")\n",
    "#wnLemm = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(ArticleDB):\n",
    "    artText = ArticleDB[\"content\"]\n",
    "    countVect = CountVectorizer(binary=True)\n",
    "    vector = countVect.fit(artText)\n",
    "    #print(X_train_counts)\n",
    "    features= countVect.vocabulary_\n",
    "    fts = list(features.keys())\n",
    "    print(len(fts))\n",
    "    print(fts)\n",
    "    \n",
    "    return artText, fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BinaryEncoding\n",
    "def RecBinaryEncoding(fts, artText):\n",
    "    print(\"bin Encoding\")\n",
    "    df_rows = []\n",
    "    #tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    for art in tqdm(artText):\n",
    "        if type(art) == str: \n",
    "            body = art.lower()\n",
    "            body = body.split() \n",
    "            wordsCounter = Counter(body)\n",
    "            df_rows.append([1 if word in wordsCounter else 0 for word in fts])\n",
    "        else:\n",
    "            df_rows.append([0 for word in fts])\n",
    "    X = pd.DataFrame(df_rows, columns = fts)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term Freq. Encoding\n",
    "def TfEncoding(fts, artText):\n",
    "    print(\"tf Encoding\")\n",
    "    tf_rows = []\n",
    "    \n",
    "    for art in tqdm(artText):\n",
    "        if type(art) == str:\n",
    "            body = art.lower()\n",
    "            body = body.split()\n",
    "            wordsCounter = Counter(body)\n",
    "            tf_rows.append([wordsCounter[word] if word in wordsCounter else 0 for word in fts])\n",
    "        else:\n",
    "            tf_rows.append([0 for word in fts])\n",
    "    X = pd.DataFrame(tf_rows, columns = fts)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term Frequency - inverse document frequency encoding\n",
    "def tfidfEncoding(fts, artText):\n",
    "    print(\"tifidf Encoding\")\n",
    "\n",
    "    # Base calculations\n",
    "    binX = RecBinaryEncoding(fts, artText)\n",
    "    tfX = TfEncoding(fts, artText)\n",
    "    \n",
    "    # Calculate idf\n",
    "    df_row = [binX[word].sum() for word in fts]\n",
    "    idf = [1/(df+1) for df in df_row]\n",
    "    #transpose list (not the cleverest method)\n",
    "    idf_row = []\n",
    "    idf_row.append(idf)\n",
    "    idf_list = pd.DataFrame(idf_row, columns = fts)\n",
    "    \n",
    "    # Extract term frequencies\n",
    "    tf = tfX.values\n",
    "    # Set up loop to multiply each article (row) by the idf per term (col)\n",
    "    tf_idf = []\n",
    "    r, c = tf.shape\n",
    "    for art in range(0,r):\n",
    "        tf_idf.append(tf[art]*idf)\n",
    "    tf_idf = pd.DataFrame(tf_idf, columns = fts)\n",
    "    X = tf_idf\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosinepairup(npV, rows, Y):\n",
    "    for i in range(rows):\n",
    "        #find most related articles indexed\n",
    "        a = npV[i,:]\n",
    "        index = np.argpartition(a, -4)[-4:]\n",
    "        index2= index[np.argsort(a[index])]\n",
    "\n",
    "        #show the index in X matrix\n",
    "        #print(i)\n",
    "        #print(index)\n",
    "        #print(index2)\n",
    "        #show the similarity value\n",
    "        #print(a[index2])\n",
    "\n",
    "        related = []\n",
    "        #ensure that same article is not ranked as the most similar article\n",
    "        for j in range(3,-1,-1):\n",
    "            if i == index2[j]:\n",
    "                pass #do not count the same article as most related\n",
    "            elif len(related) == 3:\n",
    "                pass\n",
    "            else:\n",
    "                related.append(str(index2[j]))\n",
    "\n",
    "        Y.at[i, 'related_articles'] = ', '.join(related)\n",
    "\n",
    "    return Y[['related_articles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(ArticleDB):\n",
    "    \n",
    "    #Get Features\n",
    "    artText, fts = getFeatures(ArticleDB)\n",
    "    \n",
    "    #Default encoding is tf-idf\n",
    "    Encoded = tfidfEncoding(fts, artText)\n",
    "    \n",
    "    \n",
    "    #Similarity matrix between each article\n",
    "    Csim = cosine_similarity(Encoded)\n",
    "\n",
    "    #convert to numpy\n",
    "    npV = np.asarray(Csim)\n",
    "    rows = np.size(npV,0)\n",
    "\n",
    "    \n",
    "    #match most related articles by article index\n",
    "    finalMatches = Cosinepairup(npV, rows, Encoded)\n",
    "    finalTable = ArticleDB.join(finalMatches, how='left')\n",
    "    \n",
    "    return finalTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:05<00:00, 123.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#binEncoded = RecBinaryEncoding(fts, artText)\n",
    "#binEncoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:03<00:00, 179.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preview</th>\n",
       "      <th>research</th>\n",
       "      <th>report</th>\n",
       "      <th>business</th>\n",
       "      <th>insider</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>premium</th>\n",
       "      <th>service</th>\n",
       "      <th>learn</th>\n",
       "      <th>click</th>\n",
       "      <th>...</th>\n",
       "      <th>legitimately</th>\n",
       "      <th>plumped</th>\n",
       "      <th>misconceived</th>\n",
       "      <th>creeping</th>\n",
       "      <th>favoured</th>\n",
       "      <th>mooted</th>\n",
       "      <th>revitalise</th>\n",
       "      <th>piecemeal</th>\n",
       "      <th>tyrie</th>\n",
       "      <th>mettle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25293 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   preview  research  report  business  insider  intelligence  premium  \\\n",
       "0        1         3      10         6        6             5        2   \n",
       "1        0         0       7         2        0             5        0   \n",
       "2        0         0       1         0        0             0        0   \n",
       "3        0         0       1         0        0             0        0   \n",
       "4        0         0       0         2        2             0        0   \n",
       "\n",
       "   service  learn  click   ...    legitimately  plumped  misconceived  \\\n",
       "0        1      2      1   ...               0        0             0   \n",
       "1        2      0      0   ...               0        0             0   \n",
       "2        0      0      1   ...               0        0             0   \n",
       "3        0      0      1   ...               0        0             0   \n",
       "4        0      0      1   ...               0        0             0   \n",
       "\n",
       "   creeping  favoured  mooted  revitalise  piecemeal  tyrie  mettle  \n",
       "0         0         0       0           0          0      0       0  \n",
       "1         0         0       0           0          0      0       0  \n",
       "2         0         0       0           0          0      0       0  \n",
       "3         0         0       0           0          0      0       0  \n",
       "4         0         0       0           0          0      0       0  \n",
       "\n",
       "[5 rows x 25293 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfEncoded = TfEncoding(fts,artText)\n",
    "#tfEncoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tifidf Encoding\n",
      "bin Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:02<00:00, 217.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619/619 [00:03<00:00, 202.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preview</th>\n",
       "      <th>research</th>\n",
       "      <th>report</th>\n",
       "      <th>business</th>\n",
       "      <th>insider</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>premium</th>\n",
       "      <th>service</th>\n",
       "      <th>learn</th>\n",
       "      <th>click</th>\n",
       "      <th>...</th>\n",
       "      <th>legitimately</th>\n",
       "      <th>plumped</th>\n",
       "      <th>misconceived</th>\n",
       "      <th>creeping</th>\n",
       "      <th>favoured</th>\n",
       "      <th>mooted</th>\n",
       "      <th>revitalise</th>\n",
       "      <th>piecemeal</th>\n",
       "      <th>tyrie</th>\n",
       "      <th>mettle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.062112</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    preview  research    report  business   insider  intelligence   premium  \\\n",
       "0  0.142857  0.032258  0.062112  0.022814  0.082192      0.111111  0.117647   \n",
       "1  0.000000  0.000000  0.043478  0.007605  0.000000      0.111111  0.000000   \n",
       "2  0.000000  0.000000  0.006211  0.000000  0.000000      0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.006211  0.000000  0.000000      0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.007605  0.027397      0.000000  0.000000   \n",
       "\n",
       "    service     learn     click   ...    legitimately  plumped  misconceived  \\\n",
       "0  0.009259  0.064516  0.015152   ...             0.0      0.0           0.0   \n",
       "1  0.018519  0.000000  0.000000   ...             0.0      0.0           0.0   \n",
       "2  0.000000  0.000000  0.015152   ...             0.0      0.0           0.0   \n",
       "3  0.000000  0.000000  0.015152   ...             0.0      0.0           0.0   \n",
       "4  0.000000  0.000000  0.015152   ...             0.0      0.0           0.0   \n",
       "\n",
       "   creeping  favoured  mooted  revitalise  piecemeal  tyrie  mettle  \n",
       "0       0.0       0.0     0.0         0.0        0.0    0.0     0.0  \n",
       "1       0.0       0.0     0.0         0.0        0.0    0.0     0.0  \n",
       "2       0.0       0.0     0.0         0.0        0.0    0.0     0.0  \n",
       "3       0.0       0.0     0.0         0.0        0.0    0.0     0.0  \n",
       "4       0.0       0.0     0.0         0.0        0.0    0.0     0.0  \n",
       "\n",
       "[5 rows x 25231 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidfEncoded = tfidfEncoding(fts, artText)\n",
    "#tfidfEncoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#finalTable = recommender(tfidfEncoded, ArticleDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nonRel</th>\n",
       "      <th>Rel</th>\n",
       "      <th>url</th>\n",
       "      <th>prediction</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>origContent</th>\n",
       "      <th>related_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194252</td>\n",
       "      <td>0.805748</td>\n",
       "      <td>https://www.businessinsider.com/the-us-home-he...</td>\n",
       "      <td>1</td>\n",
       "      <td>THE US HOME HEALTHCARE REPORT: How US provider...</td>\n",
       "      <td>This is a preview of a research report from Bu...</td>\n",
       "      <td>business-insider</td>\n",
       "      <td>2019-02-20T15:34:00Z</td>\n",
       "      <td>This is a preview of a research report from Bu...</td>\n",
       "      <td>This is a preview of a research report from Bu...</td>\n",
       "      <td>12, 431, 365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.202238</td>\n",
       "      <td>0.797762</td>\n",
       "      <td>https://www.washingtonpost.com/news/powerpost/...</td>\n",
       "      <td>1</td>\n",
       "      <td>The Technology 202: The British come to Silico...</td>\n",
       "      <td>And it may not be such a friendly visit.</td>\n",
       "      <td>the-washington-post</td>\n",
       "      <td>2019-02-19T13:55:26Z</td>\n",
       "      <td>Ctrl   N FILES  In this file photo taken on Ma...</td>\n",
       "      <td>Ctrl + N\\r\\n(FILES) In this file photo taken o...</td>\n",
       "      <td>175, 120, 519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.223153</td>\n",
       "      <td>0.776847</td>\n",
       "      <td>https://www.foxnews.com/politics/trump-venezue...</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump declares 'socialism is dying' amid Venez...</td>\n",
       "      <td>Trump declares 'socialism is dying' amid Venez...</td>\n",
       "      <td>fox-news</td>\n",
       "      <td>2019-02-18T22:42:05Z</td>\n",
       "      <td>President Donald Trump  speaking in a major fo...</td>\n",
       "      <td>President Donald Trump, speaking in a major fo...</td>\n",
       "      <td>3, 482, 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.223153</td>\n",
       "      <td>0.776847</td>\n",
       "      <td>https://www.foxnews.com/politics/trump-venezue...</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump declares 'socialism is dying' amid Venez...</td>\n",
       "      <td>Trump declares 'socialism is dying' amid Venez...</td>\n",
       "      <td>fox-news</td>\n",
       "      <td>2019-02-18T22:42:05Z</td>\n",
       "      <td>President Donald Trump  speaking in a major fo...</td>\n",
       "      <td>President Donald Trump, speaking in a major fo...</td>\n",
       "      <td>2, 482, 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225160</td>\n",
       "      <td>0.774840</td>\n",
       "      <td>https://www.businessinsider.com/alaska-permane...</td>\n",
       "      <td>1</td>\n",
       "      <td>The political debate over Alaska's universal c...</td>\n",
       "      <td>The Alaska Permanent Fund is a $65 billion fun...</td>\n",
       "      <td>business-insider</td>\n",
       "      <td>2019-02-20T20:59:28Z</td>\n",
       "      <td>Alaska s permanent fund and its annual univers...</td>\n",
       "      <td>Alaska's permanent fund and its annual univers...</td>\n",
       "      <td>105, 319, 59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nonRel       Rel                                                url  \\\n",
       "0  0.194252  0.805748  https://www.businessinsider.com/the-us-home-he...   \n",
       "1  0.202238  0.797762  https://www.washingtonpost.com/news/powerpost/...   \n",
       "2  0.223153  0.776847  https://www.foxnews.com/politics/trump-venezue...   \n",
       "3  0.223153  0.776847  https://www.foxnews.com/politics/trump-venezue...   \n",
       "4  0.225160  0.774840  https://www.businessinsider.com/alaska-permane...   \n",
       "\n",
       "   prediction                                              title  \\\n",
       "0           1  THE US HOME HEALTHCARE REPORT: How US provider...   \n",
       "1           1  The Technology 202: The British come to Silico...   \n",
       "2           1  Trump declares 'socialism is dying' amid Venez...   \n",
       "3           1  Trump declares 'socialism is dying' amid Venez...   \n",
       "4           1  The political debate over Alaska's universal c...   \n",
       "\n",
       "                                         description               source  \\\n",
       "0  This is a preview of a research report from Bu...     business-insider   \n",
       "1           And it may not be such a friendly visit.  the-washington-post   \n",
       "2  Trump declares 'socialism is dying' amid Venez...             fox-news   \n",
       "3  Trump declares 'socialism is dying' amid Venez...             fox-news   \n",
       "4  The Alaska Permanent Fund is a $65 billion fun...     business-insider   \n",
       "\n",
       "                   date                                            content  \\\n",
       "0  2019-02-20T15:34:00Z  This is a preview of a research report from Bu...   \n",
       "1  2019-02-19T13:55:26Z  Ctrl   N FILES  In this file photo taken on Ma...   \n",
       "2  2019-02-18T22:42:05Z  President Donald Trump  speaking in a major fo...   \n",
       "3  2019-02-18T22:42:05Z  President Donald Trump  speaking in a major fo...   \n",
       "4  2019-02-20T20:59:28Z  Alaska s permanent fund and its annual univers...   \n",
       "\n",
       "                                         origContent related_articles  \n",
       "0  This is a preview of a research report from Bu...     12, 431, 365  \n",
       "1  Ctrl + N\\r\\n(FILES) In this file photo taken o...    175, 120, 519  \n",
       "2  President Donald Trump, speaking in a major fo...        3, 482, 9  \n",
       "3  President Donald Trump, speaking in a major fo...        2, 482, 9  \n",
       "4  Alaska's permanent fund and its annual univers...     105, 319, 59  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finalTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalTable.to_excel(\"TFidfEncodedNewStop.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
