{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding\n",
    "\n",
    "The following script formats articles by features for linear regression (first attempt).  \n",
    "It takes in a list of features and a set of articles, converts to lowercase and creates an encoded matrix (dense)  \n",
    "While this isn't the cleverest method, it provides a usable input for setting up our initial linear regression code.\n",
    "\n",
    "### Limitations:\n",
    "* Proper Nouns should keep their capitals\n",
    "* Punctuation/Stemming etc not incorporated\n",
    "* Bi-grams not accommodated\n",
    "* Could be converted to space matrix\n",
    "* No log function incorporated at this point\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyscripter\n",
    "\n",
    "#relevant_nbs = ['FeatureSelection.ipynb']\n",
    "#relevant_nbs = pyscripter.nb_to_py(relevant_nbs)\n",
    "#print(\"y print 2x?\")\n",
    "#print(relevant_nbs)\n",
    "#pyscripter.import_scripts(['FeatureSelection.py'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    DATA_DIR = \"Data\"\n",
    "    FEATURES_DIR = os.path.join(DATA_DIR, \"retailFeatureSet.csv\")\n",
    "    ARTICLES_DIR = os.path.join(DATA_DIR, \"retailarticles YTD (new)_merged.csv\")\n",
    "    \n",
    "    fts = pd.read_csv(FEATURES_DIR)\n",
    "    for col in fts.columns:\n",
    "        if not (col.strip() == 'target_group'):\n",
    "            fts = fts.drop([col], axis = 1)\n",
    "    fts.columns = ['index']\n",
    "    fts['index'] = list(map(lambda x: x.strip(), fts['index']))\n",
    "    arts = pd.read_csv(ARTICLES_DIR)\n",
    "    artText = arts.iloc[:,5]\n",
    "    data = {'fts':fts, 'artText': artText}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binEncoding(data):\n",
    "    print(\"Binary Encoding\")\n",
    "    fts = data['fts']\n",
    "    artText = data['artText']\n",
    "    \n",
    "    df_rows = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    for art in artText:\n",
    "        if type(art) == str: \n",
    "            body = art.lower()\n",
    "            #body = clean_file_text(body)\n",
    "            art_words = tokenizer.tokenize(body)\n",
    "            df_rows.append([1 if word in art_words else 0 for word in fts['index']])\n",
    "        else:\n",
    "            df_rows.append([0 for word in fts['index']])\n",
    "    X = pd.DataFrame(df_rows, columns = fts['index'].values)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfEncoding(data):\n",
    "    print(\"tf Encoding\")\n",
    "    fts = data['fts']\n",
    "    artText = data['artText']\n",
    "    \n",
    "    tf_rows = []\n",
    "    for art in artText:\n",
    "        if type(art) == str:\n",
    "            body = art.lower()\n",
    "            body = body.split()\n",
    "            wordsCounter = Counter(body)\n",
    "            tf_rows.append([wordsCounter[word] if word in wordsCounter else 0 for word in fts['index']])\n",
    "        else:\n",
    "            tf_rows.append([0 for word in fts['index']])\n",
    "    X = pd.DataFrame(tf_rows, columns = fts['index'].values)  \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', 'stores', 'retailers', 'brands', 'company', 'store',\n",
       "       'sales', 'brand', 'gap', 'retail', 'economic', 'companys',\n",
       "       'online', 'government', 'shares', 'google', 'since', 'however',\n",
       "       'economy', 'employers', 'reported', 'asked', 'markets', 'law',\n",
       "       'gt', 'instead', 'finance', 'largely', 'committee', 'age', 'area',\n",
       "       'consumer', 'quarter', '2020', 'data', 'harassment', 'comes',\n",
       "       'inflation', 'steel', 'rich', 'bad', 'budget', 'jobs', 'risks',\n",
       "       'software', 'cant', 'reason', 'levels', 'revenue', 'provide',\n",
       "       'york', 'male', 'increases', 'pension', 'show', 'opportunities',\n",
       "       'policies', 'governments', 'treasury', 'come', 'less',\n",
       "       'university', 'minister', 'amount', 'elections', 'lead', 'goldman',\n",
       "       'economist', 'administration', 'customers', 'tend', 'spent',\n",
       "       'womens', 'already', 'policy', 'smaller', 'follow', 'work', 'step',\n",
       "       'western', 'role', 'monetary', 'cities', 'profits', 'announced',\n",
       "       'market', 'between', 'paid', 'hes', 'economies', 'children',\n",
       "       'create', 'may', 'sanctions', 'prime', 'international', 'lot',\n",
       "       'analysts', 'results', 'canada', 'countries', 'car', 'businesses',\n",
       "       'success', 'room', 'experience', 'profit', 'domestic', 'according',\n",
       "       'even', 'rules', 'left', 'turn', 'september', 'result', 'dollar',\n",
       "       'russia', 'united', 'terms', 'public', 'family', 'need', 'view',\n",
       "       'yield', 'against', 'stock', 'hit', 'ceo', 'comment', 'analysis',\n",
       "       'taking', 'progress', 'position', 'billion', 'made', 'north',\n",
       "       'corporate', 'output', '30', 'global', 'please', 'sell', 'enough',\n",
       "       'republican', 'arent', 'really', 'nothing', 'retirement', 'year',\n",
       "       'partner', 'top', 'kind', 'contact', 'course', 'whats', 'former',\n",
       "       'wages', 'taxes', 'away', 'bonds', 'problem', 'crisis',\n",
       "       'relationship', 'key', 'space', 'perhaps', 'act', 'cent', 'bank',\n",
       "       'mean', 'country', 'lack', 'response', 'operating', 'works',\n",
       "       'want', 'american', 'post', 'several', 'fact', 'campaign',\n",
       "       'council', 'meeting', 'white', 'services', 'traditional', 'order',\n",
       "       'forecast', 'central', 'point', 'reality', 'spending', 'line',\n",
       "       'unemployment', 'reserve', 'bond', 'recent', 'quickly', 'june',\n",
       "       'meanwhile', 'tesla', 'america', 'hours', 'high', 'apple',\n",
       "       'california', 'term', 'actually', 'deal', 'gross', 'poor',\n",
       "       'series', 'particularly', 'selling', 'investor', 'fund', 'rate',\n",
       "       'federal', 'ability', 'five', 'end', 'still', 'executive', 'shows',\n",
       "       'leading', 'chairman', 'challenge', 'per', 'asia', 'towards',\n",
       "       'companies', 'forecasts', 'students', 'interest', 'management',\n",
       "       'areas', 'done', 'twitter', '2015', 'october', 'competition',\n",
       "       'political', 'major', 'theyre', 'agency', 'review', 'ms',\n",
       "       'following', 'measure'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadData()\n",
    "fts = data['fts']\n",
    "fts['index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfEncoding(data):\n",
    "    print(\"tifidf Encoding\")\n",
    "    fts = data['fts']\n",
    "\n",
    "    # Base calculations\n",
    "    binX = binEncoding(data)\n",
    "    tfX = tfEncoding(data)\n",
    "    \n",
    "    # Calculate idf\n",
    "    df_row = [binX[word].sum() for word in fts['index']]\n",
    "    idf = [1/(df+1) for df in df_row]\n",
    "    #transpose list (not the cleverest method)\n",
    "    idf_row = []\n",
    "    idf_row.append(idf)\n",
    "    idf_list = pd.DataFrame(idf_row, columns = fts['index'])\n",
    "    \n",
    "    # Extract term frequencies\n",
    "    tf = tfX.values\n",
    "    # Set up loop to multiply each article (row) by the idf per term (col)\n",
    "    tf_idf = []\n",
    "    r, c = tf.shape\n",
    "    for art in range(0,r):\n",
    "        tf_idf.append(tf[art]*idf)\n",
    "    tf_idf = pd.DataFrame(tf_idf, columns = fts['index'])\n",
    "    X = tf_idf\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tifidf Encoding\n",
      "tf Encoding\n"
     ]
    }
   ],
   "source": [
    "print(\"tifidf Encoding\")\n",
    "data = loadData()\n",
    "fts = data['fts']\n",
    "\n",
    "# Base calculations\n",
    "binX = binEncoding(data)\n",
    "tfX = tfEncoding(data)\n",
    "\n",
    "# Calculate idf\n",
    "#df_row = [binX[word].sum() for word in fts['index']]\n",
    "#idf = [1/(df+1) for df in df_row]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "1130\n",
      "597\n",
      "476\n",
      "512\n",
      "3619\n",
      "365\n",
      "1513\n",
      "426\n",
      "5461\n",
      "639\n",
      "2565\n",
      "723\n",
      "769\n",
      "3391\n",
      "1000\n",
      "621\n",
      "3392\n",
      "1201\n",
      "2434\n",
      "545\n",
      "840\n",
      "595\n",
      "2083\n",
      "897\n",
      "600\n",
      "583\n",
      "922\n",
      "399\n",
      "493\n",
      "608\n",
      "452\n",
      "683\n",
      "1018\n",
      "425\n",
      "2783\n",
      "434\n",
      "889\n",
      "1370\n",
      "396\n",
      "527\n",
      "486\n",
      "1348\n",
      "1227\n",
      "577\n",
      "383\n",
      "595\n",
      "578\n",
      "682\n",
      "860\n",
      "668\n",
      "845\n",
      "624\n",
      "392\n",
      "525\n",
      "892\n",
      "382\n",
      "650\n",
      "829\n",
      "606\n",
      "1401\n",
      "2452\n",
      "1009\n",
      "1006\n",
      "474\n",
      "435\n",
      "618\n",
      "409\n",
      "602\n",
      "783\n",
      "706\n",
      "382\n",
      "439\n",
      "470\n",
      "1383\n",
      "2068\n",
      "458\n",
      "388\n",
      "2547\n",
      "426\n",
      "358\n",
      "696\n",
      "638\n",
      "537\n",
      "474\n",
      "650\n",
      "4555\n",
      "3813\n",
      "1015\n",
      "459\n",
      "433\n",
      "777\n",
      "591\n",
      "3953\n",
      "430\n",
      "689\n",
      "1234\n",
      "1223\n",
      "840\n",
      "596\n",
      "942\n",
      "2042\n",
      "486\n",
      "919\n",
      "424\n",
      "360\n",
      "523\n",
      "455\n",
      "731\n",
      "3488\n",
      "3573\n",
      "772\n",
      "883\n",
      "478\n",
      "466\n",
      "675\n",
      "1022\n",
      "579\n",
      "803\n",
      "787\n",
      "1692\n",
      "683\n",
      "2024\n",
      "589\n",
      "812\n",
      "1683\n",
      "1346\n",
      "721\n",
      "854\n",
      "403\n",
      "540\n",
      "798\n",
      "473\n",
      "471\n",
      "3068\n",
      "1854\n",
      "1220\n",
      "941\n",
      "487\n",
      "738\n",
      "2244\n",
      "382\n",
      "535\n",
      "963\n",
      "548\n",
      "429\n",
      "1185\n",
      "379\n",
      "500\n",
      "6862\n",
      "452\n",
      "1506\n",
      "514\n",
      "467\n",
      "577\n",
      "436\n",
      "1256\n",
      "447\n",
      "541\n",
      "794\n",
      "680\n",
      "993\n",
      "1052\n",
      "449\n",
      "859\n",
      "415\n",
      "477\n",
      "397\n",
      "4421\n",
      "2821\n",
      "675\n",
      "1584\n",
      "500\n",
      "422\n",
      "350\n",
      "357\n",
      "1548\n",
      "1676\n",
      "423\n",
      "821\n",
      "643\n",
      "539\n",
      "362\n",
      "741\n",
      "949\n",
      "1131\n",
      "388\n",
      "574\n",
      "517\n",
      "1332\n",
      "1269\n",
      "352\n",
      "1454\n",
      "673\n",
      "409\n",
      "433\n",
      "758\n",
      "1613\n",
      "419\n",
      "733\n",
      "508\n",
      "367\n",
      "1202\n",
      "515\n",
      "1553\n",
      "487\n",
      "352\n",
      "627\n",
      "601\n",
      "1714\n",
      "362\n",
      "529\n",
      "367\n",
      "601\n",
      "414\n",
      "505\n",
      "1342\n",
      "2096\n",
      "1083\n",
      "409\n",
      "1165\n",
      "1669\n",
      "2923\n",
      "1387\n",
      "589\n",
      "443\n",
      "462\n",
      "383\n",
      "5434\n",
      "566\n",
      "404\n",
      "4339\n",
      "351\n",
      "449\n",
      "1573\n",
      "1048\n",
      "581\n",
      "716\n",
      "409\n",
      "833\n",
      "421\n",
      "481\n",
      "1366\n",
      "873\n",
      "738\n",
      "388\n",
      "434\n",
      "637\n",
      "622\n",
      "508\n"
     ]
    }
   ],
   "source": [
    "for word in fts['index']:\n",
    "    print(tfX[word].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(encodeType, **kwargs):\n",
    "    # 0 for Binary Encoding\n",
    "    # 1 for Term Frequency Encoding\n",
    "    # 2 for TF-IDF Encoding\n",
    "    # If you'd like to save as csv, use \"csv = True\"\n",
    "        \n",
    "    # Load up data\n",
    "    data = loadData()\n",
    "    \n",
    "    # Run corresponding encoding type and pass data\n",
    "    options = {0 : binEncoding,\n",
    "                1 : tfEncoding,\n",
    "                2 : tfidfEncoding,}\n",
    "    \n",
    "    X = options[encodeType](data)\n",
    "    \n",
    "    # Save as csv file in CLASSIFICATION data folder =)\n",
    "    if ('csv' in kwargs) and (kwargs['csv']):\n",
    "        \n",
    "        # File path for this file\n",
    "        file_name = options[encodeType].__name__ + '.csv'\n",
    "        thispath = Path().absolute()\n",
    "        OUTPUT_DIR = os.path.join(thispath.parent.parent, \"Classification\", \"Data\", file_name)\n",
    "        # if the following line throws an error, use the line after to save in same folder\n",
    "        pd.DataFrame.to_csv(X, path_or_buf=OUTPUT_DIR)\n",
    "        #pd.DataFrame.to_csv(X, path_or_buf=file_name)\n",
    "    \n",
    "    # Return Panda DataFrame\n",
    "    return X\n",
    "    \n",
    "\n",
    "\n",
    "def main(): # Stuff to do when run from the command line    \n",
    "    encoding(0, csv = True)\n",
    "    pass  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Encoding\n",
      "C:\\Users\\Padmanie\\Documents\\GitHub\\Capstone\\Classification\\Data\\binEncoding.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>stores</th>\n",
       "      <th>retailers</th>\n",
       "      <th>brands</th>\n",
       "      <th>company</th>\n",
       "      <th>store</th>\n",
       "      <th>sales</th>\n",
       "      <th>brand</th>\n",
       "      <th>gap</th>\n",
       "      <th>...</th>\n",
       "      <th>october</th>\n",
       "      <th>competition</th>\n",
       "      <th>political</th>\n",
       "      <th>major</th>\n",
       "      <th>theyre</th>\n",
       "      <th>agency</th>\n",
       "      <th>review</th>\n",
       "      <th>ms</th>\n",
       "      <th>following</th>\n",
       "      <th>measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  stores  retailers  brands  company  store  sales  brand  gap  \\\n",
       "0  0  0       0          0       0        1      0      0      0    0   \n",
       "1  0  0       1          0       0        1      0      1      0    1   \n",
       "2  0  1       0          1       0        1      0      1      0    1   \n",
       "3  0  1       1          0       0        1      0      0      0    1   \n",
       "4  0  0       0          0       0        0      0      0      0    1   \n",
       "\n",
       "    ...     october  competition  political  major  theyre  agency  review  \\\n",
       "0   ...           0            0          1      0       1       0       1   \n",
       "1   ...           0            0          0      0       0       0       0   \n",
       "2   ...           0            0          0      0       0       0       0   \n",
       "3   ...           0            0          0      0       0       0       0   \n",
       "4   ...           0            0          0      0       0       0       0   \n",
       "\n",
       "   ms  following  measure  \n",
       "0   0          0        0  \n",
       "1   0          0        0  \n",
       "2   0          0        0  \n",
       "3   0          0        0  \n",
       "4   0          0        0  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testcell\n",
    "\n",
    "X = encoding(0, csv=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
