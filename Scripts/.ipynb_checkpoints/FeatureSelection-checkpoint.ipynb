{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get features (stops words removed) by tokenizing corpus - no stemming in baseline\n",
    "#Binary encoding\n",
    "#Assign target group \n",
    "#Use mutual information to get final feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import datasets\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Testing Feature Selection\n",
    "import nltk\n",
    "\n",
    "## Download Resources\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "from nltk.stem import *\n",
    "\n",
    "# download required resources\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# we'll compare two stemmers and a lemmatizer\n",
    "lrStem = LancasterStemmer()\n",
    "sbStem = SnowballStemmer(\"english\")\n",
    "prStem = PorterStemmer()\n",
    "wnLemm = WordNetLemmatizer()\n",
    "def wnLemm_v(word):\n",
    "    return WordNetLemmatizer.lemmatize(word, 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData():\n",
    "    #Import Labelled Data\n",
    "    DATA_DIR = \"Data\"\n",
    "    thispath = Path().absolute()\n",
    "    #dtype = {\"index\": str, \"title\": str, \"description\": str, \"url\": str, \"date\": str, \"Retail Relevance\": str, \"Economy Relevant\": str, \"Market moving\": str}\n",
    "    RET_ARTICLES = os.path.join(DATA_DIR, \"Labelled Articles.xlsx\")\n",
    "    \n",
    "    df = pd.read_excel(RET_ARTICLES)\n",
    "\n",
    "    try:\n",
    "        df.head()\n",
    "    except:\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignStopWords(): \n",
    "    #Stop_words list Options\n",
    "    #Variation 1: added stop words starting at 'one'\n",
    "    stop_words = stopwords = [\n",
    "        # dates/times\n",
    "        \"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"october\", \"november\", \"december\", \"jan\", \"feb\",\"mar\", \"apr\", \"jun\", \"jul\", \"aug\", \"oct\", \"nov\", \"dec\", \"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\", \"morning\", \"evening\",\n",
    "        # symbols that don't separate a sentence\n",
    "        '$','“','”','’','—',\n",
    "        # specific article terms that are useless\n",
    "        \"read\", \"share\", \"file\", \"'s\",\"i\", \"photo\", \"percent\",\"s\", \"t\", \"inc.\", \"corp\", \"group\", \"inc\", \"corp.\", \"source\", \"bloomberg\", \"cnbc\",\"cnbcs\", \"cnn\", \"reuters\",\"bbc\", \"published\", \"broadcast\",\"york\",\"msnbc\",\n",
    "        # other useless terms\n",
    "        \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"co\", \"inc\", \"com\", \"theyve\", \"theyre\", \"theres\", \"heres\", \"didnt\", \"wouldn\", \"couldn\", \"didn\",\"nbcuniversal\",\"according\", \"just\", \"us\", \"ll\", \"times\"#,\n",
    "        # etc\n",
    "        \"from\",\"the\", \"a\", \"with\", \"have\", \"has\", \"had\", \"having\", \"hello\", \"welcome\", \"yeah\", \"wasn\", \"today\", \"etc\", \"ext\",\"definitely\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"while\", \"of\", \"said\", \"by\", \"for\", \"about\", \"into\", \"through\", \"during\", \"before\", \"after\", \"to\", \"from\", \"in\", \"out\", \"with\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"just\", \"don\", \"now\", \"will\"\n",
    "        ]\n",
    "    #from nltk.corpus import stopwords\n",
    "    #stop_words = set(stopwords.words('english'))\n",
    "    #print(stop_words)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_count_words(df, stop_words, text_col = 'content', normalizer=None):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_counter = Counter()\n",
    "    for row in df.itertuples(index=True, name='Pandas'):\n",
    "            attribute = str((row, text_col))\n",
    "            file_words = tokenizer.tokenize(attribute)\n",
    "            #keep lowercased words that are not stop words as features\n",
    "            file_wordsNS = [word.lower() for word in file_words if not word.lower() in stop_words]\n",
    "            # remove words that are numbers\n",
    "            file_wordsN = [word for word in file_wordsNS if not word.isnumeric()]\n",
    "            #remove words with a word length less than 4 (i.e. 1-3)\n",
    "            file_wordsF = [word for word in file_wordsN if not len(word)<4]\n",
    "            \n",
    "            #stem\n",
    "            if normalizer:\n",
    "                file_wordsF = [normalizer(word) for word in file_wordsF]\n",
    "            \n",
    "            word_counter.update(file_wordsF)\n",
    "    return word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_cnt = corpus_count_words(df1,stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_cnt.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary encoding for features, also appends retail target group\n",
    "def binary_encode_features(newsarticles, top_words, text_col = 'content', normalizer=None):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df_rows = []\n",
    "    for row in tqdm(newsarticles.itertuples(index=True, name='Pandas')):\n",
    "            attribute = str((row, text_col))\n",
    "            file_words = tokenizer.tokenize(attribute)\n",
    "            if normalizer:\n",
    "                file_words = [normalizer(word) for word in file_words]\n",
    "            df_rows.append([1 if word.lower() in file_words else 0 for word in top_words])      \n",
    "    X = pd.DataFrame(df_rows, columns = top_words)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutualInformation(B_Encoding, y, top_words): \n",
    "    #Estimate mutual information for a discrete target variable.\n",
    "    #Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables.\n",
    "    #It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "    featureVals= mutual_info_classif(B_Encoding, y, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)\n",
    "    \n",
    "    np.asarray(featureVals)\n",
    "\n",
    "    Temp= pd.DataFrame(featureVals, columns = ['MI_Values'])\n",
    " \n",
    "    Final = Temp.assign(target_group = top_words)\n",
    "    \n",
    "    Highest_Features = Final.nlargest(10000, 'MI_Values')\n",
    "    \n",
    "    return Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFeatures(text_col = 'content', **kwargs):\n",
    "    df = importData()\n",
    "    stop_words = assignStopWords()\n",
    "    \n",
    "    if ('norm' in kwargs):\n",
    "        norm = kwargs['norm']\n",
    "        normalizers = {'lrStem' : lrStem.stem,\n",
    "                       'sbStem' : sbStem.stem,\n",
    "                       'prStem' : prStem.stem,\n",
    "                       'wnLemm' : wnLemm.lemmatize,\n",
    "                       'wnLemm-v':wnLemm_v,\n",
    "                       'baseline':None\n",
    "                      }\n",
    "        normalizer = normalizers[norm]\n",
    "    \n",
    "    #Select subset of orig data\n",
    "    #print(df.head(2))\n",
    "    df1 = df[[text_col,'market_moving']]    \n",
    "    news_cnt = corpus_count_words(df1, stop_words, text_col = text_col, normalizer = normalizer)\n",
    "    \n",
    "    print(\"starting Binary Encoding\")\n",
    "    num_features = 1000\n",
    "    top_words = [word for (word, freq) in news_cnt.most_common(num_features)]\n",
    "    B_Encoding = binary_encode_features(df1, top_words, text_col = text_col, normalizer = normalizer)\n",
    "    print(B_Encoding.head())\n",
    "    y = df['market_moving']\n",
    "    B_Encoding.assign(target_group=y)\n",
    "      \n",
    "    print(\"Finished Bin Encoding. Collecting Highest Features\")\n",
    "    Highest_Features = mutualInformation(B_Encoding, y, top_words)\n",
    "    Highest_Features = pd.DataFrame(Highest_Features)\n",
    "    \n",
    "    # Save as csv file in DATACOLLECTION data folder (bc it's needed for encoding script)\n",
    "    if ('csv' in kwargs) and (kwargs['csv']):\n",
    "        \n",
    "        # File path for this file\n",
    "        file_name = norm + text_col + 'FeatureSet.csv'\n",
    "        thispath = Path().absolute()\n",
    "        OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "        \n",
    "        # if the following line throws an error, use the line after to save in same folder\n",
    "        pd.DataFrame.to_csv(Highest_Features, path_or_buf=OUTPUT_DIR)\n",
    "        #pd.DataFrame.to_csv(Highest_Features, path_or_buf=file_name)\n",
    "    \n",
    "    print(Highest_Features)\n",
    "    return Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    HF = selectFeatures(csv = True, )\n",
    "    return HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: wnLemm-v\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [00:00, 13371.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   v\n",
      "0  1\n",
      "1  1\n",
      "2  1\n",
      "3  1\n",
      "4  1\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "   MI_Values target_group\n",
      "0          0            v\n",
      "title: lrStem\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [00:01, 1701.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   titl  index  panda  market_moving  amazon  stock  tech  market  say  wal  \\\n",
      "0     1      1      1              1       0      0     0       0    0    0   \n",
      "1     1      1      1              1       0      0     0       0    0    0   \n",
      "2     1      1      1              1       0      0     0       0    0    0   \n",
      "3     1      1      1              1       0      0     0       0    0    0   \n",
      "4     1      1      1              1       0      0     0       0    0    0   \n",
      "\n",
      "    ...    piec  squawk  nerv  traff  thank  airbnb  curb  auto  fresh  commod  \n",
      "0   ...       0       0     0      0      0       0     0     0      0       0  \n",
      "1   ...       0       0     0      0      0       0     0     0      0       0  \n",
      "2   ...       0       0     0      0      0       0     0     0      0       0  \n",
      "3   ...       0       0     0      0      0       0     0     0      0       0  \n",
      "4   ...       0       0     0      0      0       0     0     0      0       0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "     MI_Values target_group\n",
      "775   0.020903       intern\n",
      "18    0.019628      walmart\n",
      "498   0.017949        quest\n",
      "362   0.017561     competit\n",
      "635   0.016544       defend\n",
      "253   0.015900       revenu\n",
      "259   0.015670        month\n",
      "21    0.015496     facebook\n",
      "612   0.015444      favorit\n",
      "885   0.015086      nuclear\n",
      "237   0.014812       custom\n",
      "649   0.014773        avoid\n",
      "615   0.014412    antitrust\n",
      "657   0.014365         plac\n",
      "145   0.014233         whol\n",
      "466   0.014062          lif\n",
      "368   0.013892         vent\n",
      "687   0.013815       donald\n",
      "617   0.013737        stand\n",
      "370   0.013610        three\n",
      "891   0.013499         baby\n",
      "154   0.013486          act\n",
      "72    0.013338          fac\n",
      "876   0.013034      stanley\n",
      "379   0.012882          toy\n",
      "524   0.012733          soc\n",
      "973   0.012526        bonus\n",
      "676   0.012399       candid\n",
      "660   0.012367        built\n",
      "87    0.012232         help\n",
      "..         ...          ...\n",
      "661   0.000000          nor\n",
      "674   0.000000      britain\n",
      "339   0.000000          goe\n",
      "439   0.000000       alibab\n",
      "187   0.000000       launch\n",
      "188   0.000000         fear\n",
      "669   0.000000        light\n",
      "440   0.000000        larry\n",
      "667   0.000000     softbank\n",
      "666   0.000000        decid\n",
      "665   0.000000         left\n",
      "664   0.000000         mass\n",
      "189   0.000000        becom\n",
      "335   0.000000          tax\n",
      "190   0.000000          dai\n",
      "205   0.000000         seek\n",
      "659   0.000000          boe\n",
      "191   0.000000       latest\n",
      "192   0.000000         fang\n",
      "197   0.000000        chief\n",
      "198   0.000000          cut\n",
      "654   0.000000       colleg\n",
      "652   0.000000        estim\n",
      "651   0.000000        doesn\n",
      "650   0.000000        alleg\n",
      "201   0.000000    technolog\n",
      "202   0.000000       second\n",
      "203   0.000000         spot\n",
      "646   0.000000       direct\n",
      "0     0.000000         titl\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "title: sbStem\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [00:01, 1867.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   titl  index  panda  market_mov  amazon  stock  tech  market  say  wall  \\\n",
      "0     1      1      1           1       0      0     0       0    0     0   \n",
      "1     1      1      1           1       0      0     0       0    0     0   \n",
      "2     1      1      1           1       0      0     0       0    0     0   \n",
      "3     1      1      1           1       0      0     0       0    0     0   \n",
      "4     1      1      1           1       0      0     0       0    0     0   \n",
      "\n",
      "    ...    equal  visit  reject  trip  bonus  leari  author  probabl  steve  \\\n",
      "0   ...        0      0       0     0      0      0       0        0      0   \n",
      "1   ...        0      0       0     0      0      0       0        0      0   \n",
      "2   ...        0      0       0     0      0      0       0        0      0   \n",
      "3   ...        0      0       0     0      0      0       0        0      0   \n",
      "4   ...        0      0       0     0      0      0       0        0      0   \n",
      "\n",
      "   regret  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "     MI_Values target_group\n",
      "46    0.018654        store\n",
      "248   0.017043        major\n",
      "759   0.016764         hike\n",
      "87    0.016520       target\n",
      "417   0.015942        other\n",
      "583   0.015860         lost\n",
      "675   0.015630       offici\n",
      "15    0.014824      walmart\n",
      "654   0.014787       center\n",
      "686   0.014626         past\n",
      "813   0.014625       africa\n",
      "956   0.014272          run\n",
      "933   0.014268         tsla\n",
      "559   0.013865     flipkart\n",
      "75    0.013663         work\n",
      "45    0.013662         bank\n",
      "200   0.013537   transcript\n",
      "697   0.013533         quit\n",
      "13    0.013310      compani\n",
      "431   0.013215        parti\n",
      "718   0.013180        heavi\n",
      "678   0.013149        board\n",
      "616   0.013099      favorit\n",
      "337   0.012850       seller\n",
      "69    0.012828         face\n",
      "662   0.012731      payment\n",
      "776   0.012633        trust\n",
      "220   0.012429        bring\n",
      "160   0.012322         mark\n",
      "113   0.012311        offer\n",
      "..         ...          ...\n",
      "493   0.000000     acquisit\n",
      "498   0.000000      shopper\n",
      "499   0.000000       consid\n",
      "1     0.000000        index\n",
      "502   0.000000       troubl\n",
      "505   0.000000        yield\n",
      "506   0.000000        hotel\n",
      "507   0.000000       brazil\n",
      "508   0.000000          aim\n",
      "477   0.000000      currenc\n",
      "476   0.000000        lower\n",
      "474   0.000000         stop\n",
      "451   0.000000       assist\n",
      "436   0.000000         user\n",
      "437   0.000000         soar\n",
      "438   0.000000       bigger\n",
      "440   0.000000         forc\n",
      "442   0.000000       parent\n",
      "447   0.000000       behind\n",
      "448   0.000000     malaysia\n",
      "454   0.000000      scandal\n",
      "470   0.000000       streak\n",
      "457   0.000000        saudi\n",
      "459   0.000000          add\n",
      "460   0.000000        model\n",
      "462   0.000000         life\n",
      "465   0.000000     opportun\n",
      "466   0.000000     contract\n",
      "467   0.000000         john\n",
      "500   0.000000         blue\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "title: prStem\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [00:02, 1530.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   titl  index  panda  market_mov  amazon  stock  tech  market  say  wall  \\\n",
      "0     1      1      1           1       0      0     0       0    0     0   \n",
      "1     1      1      1           1       0      0     0       0    0     0   \n",
      "2     1      1      1           1       0      0     0       0    0     0   \n",
      "3     1      1      1           1       0      0     0       0    0     0   \n",
      "4     1      1      1           1       0      0     0       0    0     0   \n",
      "\n",
      "   ...    advic  equal  visit  reject  trip  bonus  leari  author  probabl  \\\n",
      "0  ...        0      0      0       0     0      0      0       0        0   \n",
      "1  ...        0      0      0       0     0      0      0       0        0   \n",
      "2  ...        0      0      0       0     0      0      0       0        0   \n",
      "3  ...        0      0      0       0     0      0      0       0        0   \n",
      "4  ...        0      0      0       0     0      0      0       0        0   \n",
      "\n",
      "   steve  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "     MI_Values target_group\n",
      "229   0.019900         long\n",
      "15    0.018796      walmart\n",
      "400   0.017129         seen\n",
      "357   0.016240         lead\n",
      "623   0.016159         slow\n",
      "540   0.015698         lure\n",
      "891   0.015438         mind\n",
      "264   0.014962       follow\n",
      "429   0.014874       equiti\n",
      "803   0.014727        loser\n",
      "849   0.014672       requir\n",
      "796   0.014644       candid\n",
      "64    0.014504        prime\n",
      "54    0.014185        watch\n",
      "75    0.013949         work\n",
      "947   0.013927       answer\n",
      "358   0.013824         case\n",
      "136   0.013742       season\n",
      "111   0.013518        close\n",
      "238   0.013513         made\n",
      "359   0.013485     forecast\n",
      "266   0.013322        depot\n",
      "730   0.013160         town\n",
      "22    0.013058         busi\n",
      "553   0.013053       depart\n",
      "466   0.012978     contract\n",
      "194   0.012905        right\n",
      "435   0.012749         mani\n",
      "4     0.012685       amazon\n",
      "269   0.012553     walgreen\n",
      "..         ...          ...\n",
      "492   0.000000        asian\n",
      "494   0.000000         love\n",
      "495   0.000000         stay\n",
      "497   0.000000        probe\n",
      "1     0.000000        index\n",
      "505   0.000000        yield\n",
      "507   0.000000       brazil\n",
      "509   0.000000        think\n",
      "512   0.000000      twitter\n",
      "478   0.000000        oracl\n",
      "476   0.000000        lower\n",
      "475   0.000000          bet\n",
      "456   0.000000         join\n",
      "439   0.000000       defens\n",
      "443   0.000000       differ\n",
      "444   0.000000         fail\n",
      "445   0.000000        becam\n",
      "448   0.000000     malaysia\n",
      "452   0.000000       confer\n",
      "454   0.000000      scandal\n",
      "458   0.000000         rich\n",
      "473   0.000000     competit\n",
      "459   0.000000          add\n",
      "461   0.000000         maci\n",
      "462   0.000000         life\n",
      "465   0.000000     opportun\n",
      "469   0.000000         boss\n",
      "470   0.000000       streak\n",
      "471   0.000000          kid\n",
      "999   0.000000        steve\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "title: wnLemm\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [00:01, 2628.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   title  index  panda  market_moving  amazon  stock  tech  market  say  wall  \\\n",
      "0      1      0      0              1       0      0     0       0    0     0   \n",
      "1      1      0      0              1       0      0     0       0    0     0   \n",
      "2      1      0      0              1       0      0     0       0    0     0   \n",
      "3      1      0      0              1       0      0     0       0    0     0   \n",
      "4      1      0      0              1       0      0     0       0    0     0   \n",
      "\n",
      "    ...    weapon  victoria  spark  able  room  citi  predicts  volatile  \\\n",
      "0   ...         0         0      0     0     0     0         0         0   \n",
      "1   ...         0         0      0     0     0     0         0         0   \n",
      "2   ...         0         0      0     0     0     0         0         0   \n",
      "3   ...         0         0      0     0     0     0         0         0   \n",
      "4   ...         0         0      0     0     0     0         0         0   \n",
      "\n",
      "   restaurant  reveal  \n",
      "0           0       0  \n",
      "1           0       0  \n",
      "2           0       0  \n",
      "3           0       0  \n",
      "4           0       0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "     MI_Values target_group\n",
      "385   0.018605       plunge\n",
      "29    0.017796      biggest\n",
      "91    0.016625         real\n",
      "214   0.016291         exec\n",
      "332   0.015594     spending\n",
      "994   0.015527         room\n",
      "997   0.015025     volatile\n",
      "123   0.014673        tesla\n",
      "441   0.014646       streak\n",
      "174   0.014559       crisis\n",
      "175   0.014160        japan\n",
      "115   0.014159        brand\n",
      "322   0.013901         bull\n",
      "65    0.013861         fund\n",
      "711   0.013642     changing\n",
      "314   0.013625         case\n",
      "117   0.013508         rate\n",
      "871   0.013144        alone\n",
      "330   0.013032     commerce\n",
      "631   0.012911         hire\n",
      "12    0.012807        trump\n",
      "303   0.012715     election\n",
      "317   0.012612        three\n",
      "34    0.012390         plan\n",
      "282   0.012250         wage\n",
      "259   0.012103       coming\n",
      "850   0.012099       enough\n",
      "784   0.012044   republican\n",
      "338   0.011987       energy\n",
      "127   0.011939     consumer\n",
      "..         ...          ...\n",
      "504   0.000000   commentary\n",
      "481   0.000000     strategy\n",
      "505   0.000000         went\n",
      "508   0.000000        union\n",
      "510   0.000000         snap\n",
      "511   0.000000         sign\n",
      "514   0.000000       supply\n",
      "515   0.000000        force\n",
      "516   0.000000        super\n",
      "482   0.000000         nike\n",
      "478   0.000000       taking\n",
      "436   0.000000     contract\n",
      "452   0.000000         ford\n",
      "437   0.000000         john\n",
      "439   0.000000  partnership\n",
      "440   0.000000     shipping\n",
      "443   0.000000         card\n",
      "446   0.000000     currency\n",
      "447   0.000000       oracle\n",
      "449   0.000000         cook\n",
      "455   0.000000       lesson\n",
      "469   0.000000      trouble\n",
      "457   0.000000      defense\n",
      "459   0.000000         foot\n",
      "462   0.000000  acquisition\n",
      "464   0.000000      shopper\n",
      "465   0.000000       search\n",
      "466   0.000000         blue\n",
      "467   0.000000         head\n",
      "999   0.000000       reveal\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "content: wnLemm-v\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [00:08, 390.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   v\n",
      "0  1\n",
      "1  1\n",
      "2  1\n",
      "3  1\n",
      "4  1\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "   MI_Values target_group\n",
      "0   0.006024            v\n",
      "content: lrStem\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [00:52, 59.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   company  year  cont  amazon  market  invest  lik  would  also  busy  ...    \\\n",
      "0        1     1     1       0       0       1    1      1     1     1  ...     \n",
      "1        1     1     1       0       1       1    1      1     1     1  ...     \n",
      "2        1     1     1       0       0       1    0      1     0     1  ...     \n",
      "3        0     1     1       0       0       0    1      1     1     0  ...     \n",
      "4        1     0     1       0       0       1    0      0     0     0  ...     \n",
      "\n",
      "   resourc  field  categ  react  bear  headlin  rank  prev  deficit  wrong  \n",
      "0        0      0      0      0     0        0     0     0        0      0  \n",
      "1        0      0      0      0     0        0     0     0        0      0  \n",
      "2        0      0      0      0     0        0     0     0        0      1  \n",
      "3        0      1      0      0     0        0     0     0        0      0  \n",
      "4        0      0      0      0     0        0     0     0        0      0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "     MI_Values target_group\n",
      "43    0.034371       retail\n",
      "62    0.032589         stor\n",
      "224   0.023566        polit\n",
      "388   0.022969          nev\n",
      "194   0.020755        elect\n",
      "333   0.019944          hap\n",
      "328   0.019209     ecommerc\n",
      "111   0.018627        onlin\n",
      "489   0.017861         test\n",
      "968   0.017363        middl\n",
      "36    0.016814          sal\n",
      "249   0.016777      success\n",
      "371   0.016433       design\n",
      "49    0.015949         real\n",
      "982   0.015905         tril\n",
      "926   0.015897       threat\n",
      "164   0.015826      walmart\n",
      "345   0.015805       appear\n",
      "14    0.015682          tim\n",
      "221   0.015680       target\n",
      "234   0.015473      biggest\n",
      "402   0.015224          vot\n",
      "166   0.015213        anoth\n",
      "342   0.014947        chain\n",
      "434   0.014936        alway\n",
      "362   0.014793       reason\n",
      "820   0.014626         ment\n",
      "618   0.014536         what\n",
      "461   0.014352   washington\n",
      "390   0.014213          let\n",
      "..         ...          ...\n",
      "551   0.000000          sid\n",
      "550   0.000000         vent\n",
      "547   0.000000         stop\n",
      "546   0.000000       websit\n",
      "545   0.000000        claim\n",
      "544   0.000000      commerc\n",
      "540   0.000000          run\n",
      "539   0.000000         wrot\n",
      "536   0.000000           al\n",
      "535   0.000000          fig\n",
      "530   0.000000        innov\n",
      "524   0.000000        known\n",
      "523   0.000000          end\n",
      "519   0.000000         cris\n",
      "518   0.000000       fortun\n",
      "514   0.000000         fast\n",
      "509   0.000000       energy\n",
      "506   0.000000        party\n",
      "505   0.000000       releas\n",
      "502   0.000000        apply\n",
      "499   0.000000        smart\n",
      "496   0.000000         item\n",
      "495   0.000000          pol\n",
      "486   0.000000          tax\n",
      "485   0.000000        quick\n",
      "484   0.000000       comput\n",
      "482   0.000000         pass\n",
      "478   0.000000        shift\n",
      "477   0.000000         ship\n",
      "500   0.000000          cit\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "content: sbStem\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [00:46, 68.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   compani  year  content  amazon  market  like  would  also  busi  index  \\\n",
      "0        1     1        1       0       0     1      1     1     1      1   \n",
      "1        1     1        1       0       1     1      1     1     1      1   \n",
      "2        1     1        1       0       0     0      1     0     1      1   \n",
      "3        0     1        1       0       0     1      1     1     0      1   \n",
      "4        1     0        1       0       0     0      0     0     0      1   \n",
      "\n",
      "    ...     artifici  cryptocurr  safeti  common  anyon  trillion  berkshir  \\\n",
      "0   ...            0           0       0       0      0         0         0   \n",
      "1   ...            0           0       0       0      0         0         0   \n",
      "2   ...            0           0       0       0      0         0         0   \n",
      "3   ...            0           0       0       0      0         0         0   \n",
      "4   ...            0           0       0       0      0         0         0   \n",
      "\n",
      "   germani  paper  resourc  \n",
      "0        0      0        0  \n",
      "1        0      0        0  \n",
      "2        0      0        0  \n",
      "3        0      0        0  \n",
      "4        0      0        0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "     MI_Values  target_group\n",
      "69    0.036669         store\n",
      "31    0.035179        retail\n",
      "786   0.027590          word\n",
      "300   0.023301      ecommerc\n",
      "30    0.023003          sale\n",
      "879   0.022767          noth\n",
      "137   0.018080       walmart\n",
      "686   0.017840          main\n",
      "873   0.017566        brexit\n",
      "481   0.017555          item\n",
      "971   0.017327         accus\n",
      "66    0.017017        govern\n",
      "941   0.016413        summer\n",
      "545   0.016400          test\n",
      "749   0.016334        disney\n",
      "108   0.016288          high\n",
      "747   0.016242          love\n",
      "680   0.015561       explain\n",
      "633   0.015320          caus\n",
      "111   0.015208         right\n",
      "604   0.015186          what\n",
      "714   0.015131          form\n",
      "721   0.015090        advanc\n",
      "496   0.015035          went\n",
      "696   0.014965         break\n",
      "77    0.014792         still\n",
      "72    0.014707          fund\n",
      "982   0.014515         appli\n",
      "97    0.014497       quarter\n",
      "807   0.014273       respect\n",
      "..         ...           ...\n",
      "627   0.000000       struggl\n",
      "662   0.000000         began\n",
      "643   0.000000          room\n",
      "660   0.000000  relationship\n",
      "659   0.000000          jeff\n",
      "658   0.000000          fail\n",
      "259   0.000000       largest\n",
      "654   0.000000     portfolio\n",
      "653   0.000000      familiar\n",
      "652   0.000000           cut\n",
      "260   0.000000          list\n",
      "649   0.000000         doubl\n",
      "648   0.000000       consult\n",
      "646   0.000000          wage\n",
      "263   0.000000          debt\n",
      "642   0.000000          warn\n",
      "628   0.000000          lose\n",
      "264   0.000000         earli\n",
      "640   0.000000          card\n",
      "265   0.000000         feder\n",
      "266   0.000000         great\n",
      "636   0.000000          seek\n",
      "269   0.000000          line\n",
      "271   0.000000          real\n",
      "272   0.000000      platform\n",
      "632   0.000000           car\n",
      "274   0.000000          term\n",
      "630   0.000000        margin\n",
      "629   0.000000    understand\n",
      "0     0.000000       compani\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "content: prStem\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [00:56, 55.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   compani  year  content  amazon  market  like  would  also  busi  index  \\\n",
      "0        1     1        1       0       0     1      1     1     1      1   \n",
      "1        1     1        1       0       1     1      1     1     1      1   \n",
      "2        1     1        1       0       0     0      1     0     1      1   \n",
      "3        0     1        1       0       0     1      1     1     0      1   \n",
      "4        1     0        1       0       0     0      0     0     0      1   \n",
      "\n",
      "    ...     artifici  cryptocurr  safeti  candid  anyon  trillion  berkshir  \\\n",
      "0   ...            0           0       0       0      0         0         0   \n",
      "1   ...            0           0       0       0      0         0         0   \n",
      "2   ...            0           0       0       0      0         0         0   \n",
      "3   ...            0           0       0       0      0         0         0   \n",
      "4   ...            0           0       0       0      0         0         0   \n",
      "\n",
      "   germani  paper  resourc  \n",
      "0        0      0        0  \n",
      "1        0      0        0  \n",
      "2        0      0        0  \n",
      "3        0      0        0  \n",
      "4        0      0        0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "     MI_Values  target_group\n",
      "31    0.037409        retail\n",
      "297   0.027751      ecommerc\n",
      "95    0.023494          know\n",
      "898   0.022699       sometim\n",
      "115   0.022149        public\n",
      "30    0.022043          sale\n",
      "49    0.021826      facebook\n",
      "248   0.021012         polit\n",
      "69    0.020644         store\n",
      "362   0.019559      challeng\n",
      "313   0.019157         chain\n",
      "80    0.018845         share\n",
      "994   0.018307         anyon\n",
      "210   0.018293         media\n",
      "66    0.018029        govern\n",
      "101   0.017932       analyst\n",
      "292   0.016956        record\n",
      "845   0.016872        overal\n",
      "822   0.016827     quarterli\n",
      "544   0.016764         stake\n",
      "896   0.016741          gave\n",
      "409   0.016597         alway\n",
      "652   0.016274  relationship\n",
      "433   0.016207         elect\n",
      "26    0.015816         trade\n",
      "590   0.015766       shopper\n",
      "140   0.014910         capit\n",
      "434   0.014895          cant\n",
      "247   0.014828        privat\n",
      "941   0.014818         chanc\n",
      "..         ...           ...\n",
      "523   0.000000        packag\n",
      "517   0.000000        websit\n",
      "685   0.000000         tweet\n",
      "715   0.000000          slow\n",
      "700   0.000000   partnership\n",
      "513   0.000000        electr\n",
      "713   0.000000       restaur\n",
      "712   0.000000         check\n",
      "711   0.000000         david\n",
      "710   0.000000        bigger\n",
      "268   0.000000          real\n",
      "269   0.000000      platform\n",
      "271   0.000000          term\n",
      "272   0.000000       control\n",
      "280   0.000000          play\n",
      "281   0.000000         lower\n",
      "699   0.000000       thought\n",
      "423   0.000000          sold\n",
      "698   0.000000        fiscal\n",
      "282   0.000000          rule\n",
      "283   0.000000           day\n",
      "293   0.000000        depart\n",
      "694   0.000000          asia\n",
      "693   0.000000        valuat\n",
      "692   0.000000       reflect\n",
      "295   0.000000        nearli\n",
      "296   0.000000        almost\n",
      "689   0.000000         exist\n",
      "424   0.000000         worth\n",
      "500   0.000000        stream\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "content: wnLemm\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [00:29, 106.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   company  year  content  amazon  market  would  also  business  index  like  \\\n",
      "0        1     1        1       0       0      1     1         1      0     0   \n",
      "1        1     1        1       0       0      1     1         1      0     1   \n",
      "2        1     1        1       0       0      1     0         1      0     0   \n",
      "3        0     1        1       0       0      1     1         0      0     1   \n",
      "4        1     0        1       0       0      0     0         0      0     0   \n",
      "\n",
      "      ...      manufacturer  skill  reality  piece  robot  prospect  jones  \\\n",
      "0     ...                 0      0        0      0      0         0      0   \n",
      "1     ...                 1      0        0      0      0         1      0   \n",
      "2     ...                 0      0        0      0      0         0      0   \n",
      "3     ...                 0      1        0      0      0         0      0   \n",
      "4     ...                 0      0        0      0      0         0      0   \n",
      "\n",
      "   dividend  sport  particular  \n",
      "0         0      0           0  \n",
      "1         0      0           0  \n",
      "2         1      0           0  \n",
      "3         0      0           0  \n",
      "4         0      0           0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "     MI_Values target_group\n",
      "87    0.040486     retailer\n",
      "254   0.034526        chain\n",
      "144   0.029663       retail\n",
      "50    0.025616        store\n",
      "358   0.023931        worth\n",
      "408   0.021474         item\n",
      "685   0.019912      premium\n",
      "436   0.019089     election\n",
      "933   0.017586          one\n",
      "24    0.017048         sale\n",
      "512   0.016936      shopper\n",
      "163   0.016413       become\n",
      "69    0.016263         dont\n",
      "613   0.016240         soon\n",
      "224   0.016121          day\n",
      "60    0.015932      country\n",
      "239   0.015834      concern\n",
      "694   0.015411        allow\n",
      "879   0.015105      changed\n",
      "925   0.014983     provides\n",
      "692   0.014614     standard\n",
      "266   0.014561         bond\n",
      "491   0.014535     together\n",
      "117   0.014488      economy\n",
      "766   0.014472       wanted\n",
      "245   0.014405    ecommerce\n",
      "532   0.014325   everything\n",
      "841   0.014272      silicon\n",
      "7     0.014266     business\n",
      "985   0.014244       police\n",
      "..         ...          ...\n",
      "218   0.000000        great\n",
      "628   0.000000   restaurant\n",
      "627   0.000000         drop\n",
      "211   0.000000      earlier\n",
      "623   0.000000     starting\n",
      "622   0.000000      feature\n",
      "621   0.000000     discount\n",
      "618   0.000000    currently\n",
      "213   0.000000         term\n",
      "615   0.000000       fiscal\n",
      "214   0.000000     spending\n",
      "612   0.000000       london\n",
      "217   0.000000         life\n",
      "610   0.000000        range\n",
      "220   0.000000         five\n",
      "593   0.000000   individual\n",
      "222   0.000000        large\n",
      "606   0.000000         asia\n",
      "605   0.000000    valuation\n",
      "604   0.000000        buyer\n",
      "223   0.000000      general\n",
      "601   0.000000         push\n",
      "600   0.000000        track\n",
      "599   0.000000      student\n",
      "227   0.000000         line\n",
      "597   0.000000       beyond\n",
      "229   0.000000        sampp\n",
      "595   0.000000        study\n",
      "594   0.000000     approach\n",
      "0     0.000000      company\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "nrms = ['wnLemm-v', 'lrStem', 'sbStem', 'prStem', 'wnLemm']\n",
    "txtcols = ['title', 'content']\n",
    "\n",
    "for txtcol in txtcols:\n",
    "    for nrm in nrms:\n",
    "        print(txtcol + ': ' + nrm)\n",
    "        selectFeatures(text_col = txtcol, norm = nrm, csv=True, )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id                                              title  \\\n",
      "0           6  Mr. Cook, Bring Back Apple's Most Important Fi...   \n",
      "1          12  These people move fast: Wealthy families are s...   \n",
      "2          18  Are GE Investors Still Tipsy on New Year's Cha...   \n",
      "3          24  What Canada can teach the US about immigration...   \n",
      "4          30          D.E. Shaw Builds Activist Stake in Lowe's   \n",
      "\n",
      "                                         description  \\\n",
      "0  The company used to say how many iPhone custom...   \n",
      "1  Wealthy families are speedy dealmakers, and th...   \n",
      "2      They seem to have gotten ahead of themselves.   \n",
      "3  Congress should look at Canada for ideas about...   \n",
      "4  Investor D.E. Shaw & Co. has built an active s...   \n",
      "\n",
      "                                                 url                date  \\\n",
      "0  https://www.bloomberg.com/gadfly/articles/2018... 2018-01-11 14:57:45   \n",
      "1  https://www.bloomberg.com/professional/blog/pe... 2018-01-11 22:04:44   \n",
      "2  https://www.bloomberg.com/gadfly/articles/2018... 2018-01-12 13:00:12   \n",
      "3  https://www.cnbc.com/2018/01/12/on-immigration... 2018-01-12 16:11:00   \n",
      "4  https://www.bloomberg.com/news/articles/2018-0... 2018-01-12 19:50:07   \n",
      "\n",
      "                                             content  Classify  market_moving  \n",
      "0  Permit me to nerd out on an essential baromete...         1              0  \n",
      "1  Theres a network thats growing of the big fami...         1              0  \n",
      "2  Beware of false starts at General Electric Co ...         1              0  \n",
      "3  Raising and educating children is expensive Th...         1              0  \n",
      "4  Investor DE Shaw amp Co has built an active st...         1              0  \n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [04:01, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   compani  year  content  amazon  market  like  would  also  busi  index  \\\n",
      "0        0     1        1       0       0     0      1     1     0      0   \n",
      "1        0     1        1       0       0     1      1     1     0      0   \n",
      "2        0     1        1       0       0     0      1     0     0      0   \n",
      "3        0     1        1       0       0     1      1     1     0      0   \n",
      "4        0     0        1       0       0     0      0     0     0      0   \n",
      "\n",
      "     ...     cage  onlook  kim  depositor  barb  techcrunch  vein  overreach  \\\n",
      "0    ...        0       0    0          0     0           0     0          0   \n",
      "1    ...        0       0    0          0     0           0     0          0   \n",
      "2    ...        0       0    0          0     0           0     0          0   \n",
      "3    ...        0       0    0          0     0           0     0          0   \n",
      "4    ...        0       0    0          0     0           0     0          0   \n",
      "\n",
      "   multist  sclerosi  \n",
      "0        0         0  \n",
      "1        0         0  \n",
      "2        0         0  \n",
      "3        0         0  \n",
      "4        0         0  \n",
      "\n",
      "[5 rows x 10000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\Padmanie\\\\Documents\\\\GitHub\\\\Capstone\\\\DataCollection\\\\Scripts\\\\Data\\\\lr-stem-test-retailFeatureSet-MI.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-cb9946b92fd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mHighest_Features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Let Paddy know the code is done:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwinsound\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m  \u001b[1;31m# millisecond\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-315ea39e4a3e>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mHF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselectFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mHF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-473163fde97a>\u001b[0m in \u001b[0;36mselectFeatures\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# if the following line throws an error, use the line after to save in same folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHighest_Features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;31m#pd.DataFrame.to_csv(Highest_Features, path_or_buf=file_name)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    155\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\Padmanie\\\\Documents\\\\GitHub\\\\Capstone\\\\DataCollection\\\\Scripts\\\\Data\\\\lr-stem-test-retailFeatureSet-MI.csv'"
     ]
    }
   ],
   "source": [
    "Highest_Features = main()\n",
    "\n",
    "# Let Paddy know the code is done:\n",
    "import winsound\n",
    "duration = 1000  # millisecond\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)\n",
    "winsound.Beep(600, 500)\n",
    "winsound.Beep(freq, duration)\n",
    "winsound.Beep(600, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # millisecond\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)\n",
    "winsound.Beep(600, 500)\n",
    "winsound.Beep(freq, duration)\n",
    "winsound.Beep(600, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet = pd.DataFrame(Highest_Features['target_group'])\n",
    "    \n",
    "# Save as csv file in DATACOLLECTION data folder (bc it's needed for encoding script)\n",
    "\n",
    "\n",
    "# File path for this file\n",
    "file_name = 'retailFeatureSet.csv'\n",
    "thispath = Path().absolute()\n",
    "OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "\n",
    "# if the following line throws an error, use the line after to save in same folder\n",
    "pd.DataFrame.to_csv(featureSet, path_or_buf=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Highest_Features['MI_Values'].values)\n",
    "plt.ylabel('MI Score')\n",
    "plt.axis([0, 250, 0, 0.16])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15685016, 0.08263148, 0.08260702, 0.07286888, 0.0727404 ,\n",
       "       0.0654984 , 0.06318497, 0.05706316, 0.05342845, 0.05229887,\n",
       "       0.04736192, 0.04527032, 0.03910597, 0.0382909 , 0.03785268,\n",
       "       0.03732769, 0.03720455, 0.03714783, 0.0370412 , 0.03674766,\n",
       "       0.03660287, 0.0365798 , 0.03439267, 0.03418774, 0.03344898,\n",
       "       0.0327996 , 0.03204193, 0.03201651, 0.03143229, 0.0311371 ,\n",
       "       0.03046653, 0.02992761, 0.02967316, 0.02956049, 0.02928386,\n",
       "       0.02852677, 0.0283682 , 0.02813763, 0.02805806, 0.02797806,\n",
       "       0.0274677 , 0.02681647, 0.02657687, 0.02647535, 0.02632202,\n",
       "       0.02631743, 0.02626254, 0.02589552, 0.02561664, 0.02521897,\n",
       "       0.02488037, 0.02471711, 0.02451793, 0.0243018 , 0.02428727,\n",
       "       0.02358891, 0.02354837, 0.02335415, 0.02304278, 0.0228199 ,\n",
       "       0.02278789, 0.02273341, 0.02271051, 0.02265611, 0.0225839 ,\n",
       "       0.02241316, 0.02238736, 0.02237391, 0.02223753, 0.02202336,\n",
       "       0.02195768, 0.02182063, 0.02170697, 0.02108735, 0.02104781,\n",
       "       0.02101601, 0.0206972 , 0.02022249, 0.02014468, 0.02009752,\n",
       "       0.02003192, 0.02002081, 0.01992059, 0.01953753, 0.01944085,\n",
       "       0.01932953, 0.01925128, 0.01921858, 0.019177  , 0.01912073,\n",
       "       0.01878469, 0.01876031, 0.01819669, 0.01800605, 0.01788864,\n",
       "       0.01781546, 0.01769696, 0.01766886, 0.01748472, 0.01745597,\n",
       "       0.01719029, 0.0171628 , 0.01707625, 0.01687403, 0.01678298,\n",
       "       0.01665261, 0.01659525, 0.01657155, 0.01654005, 0.0162773 ,\n",
       "       0.01623894, 0.01621432, 0.01614828, 0.01606001, 0.01601459,\n",
       "       0.01575246, 0.01573945, 0.0155525 , 0.01543243, 0.01542022,\n",
       "       0.01526572, 0.0152326 , 0.0151825 , 0.01513105, 0.01506344,\n",
       "       0.0149539 , 0.01493832, 0.01484681, 0.01483643, 0.01483036,\n",
       "       0.01482964, 0.01482309, 0.01467814, 0.01467538, 0.01423805,\n",
       "       0.01423566, 0.01422611, 0.0141962 , 0.01415151, 0.01413871,\n",
       "       0.01409401, 0.01404255, 0.01401697, 0.01398029, 0.01395775,\n",
       "       0.01395582, 0.01380354, 0.01368303, 0.01361411, 0.01346405,\n",
       "       0.01345424, 0.01341171, 0.01336537, 0.01329642, 0.01328845,\n",
       "       0.013248  , 0.01316324, 0.01312931, 0.01309673, 0.01307972,\n",
       "       0.01304401, 0.01300114, 0.01297728, 0.01294217, 0.01293249,\n",
       "       0.01292157, 0.01277577, 0.01261388, 0.01255833, 0.01254013,\n",
       "       0.01252586, 0.01242572, 0.0124206 , 0.01240847, 0.01239289,\n",
       "       0.01238173, 0.0123756 , 0.0123511 , 0.01221895, 0.01221107,\n",
       "       0.01220684, 0.01210398, 0.01208601, 0.01207174, 0.01204127,\n",
       "       0.01190933, 0.01189506, 0.01182776, 0.01175428, 0.0117343 ,\n",
       "       0.01170031, 0.01169628, 0.01168227, 0.01166558, 0.01163642,\n",
       "       0.01161614, 0.01158428, 0.01153784, 0.01143798, 0.01142473,\n",
       "       0.01141251, 0.01137744, 0.01136863, 0.01135992, 0.01128695,\n",
       "       0.01122754, 0.011183  , 0.0111815 , 0.01110504, 0.01104444,\n",
       "       0.01101577, 0.01101385, 0.01094865, 0.01088758, 0.01088383,\n",
       "       0.01086328, 0.01084084, 0.01080057, 0.01077004, 0.01076268,\n",
       "       0.01054403, 0.01047498, 0.0103773 , 0.01036865, 0.01030642,\n",
       "       0.01027068, 0.01024832, 0.01024157, 0.01018221, 0.01017854,\n",
       "       0.01015532, 0.01009939, 0.01008728, 0.01008393, 0.01007949,\n",
       "       0.01001573, 0.00997922, 0.0099745 , 0.00996542, 0.00994597,\n",
       "       0.00993376, 0.00992274, 0.00990525, 0.00982821, 0.00980088,\n",
       "       0.00976811, 0.00973395, 0.00972009, 0.00971938, 0.00969105])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Highest_Features['MI_Values'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_Values</th>\n",
       "      <th>target_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.159686</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.077075</td>\n",
       "      <td>stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.076992</td>\n",
       "      <td>inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.073780</td>\n",
       "      <td>store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.073689</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.073004</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.071416</td>\n",
       "      <td>retailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.066799</td>\n",
       "      <td>central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.064056</td>\n",
       "      <td>monetary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.059455</td>\n",
       "      <td>online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.054429</td>\n",
       "      <td>retailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.054317</td>\n",
       "      <td>commerce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.053864</td>\n",
       "      <td>rates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.050378</td>\n",
       "      <td>policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.047525</td>\n",
       "      <td>grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.045601</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.045039</td>\n",
       "      <td>interest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044477</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.044253</td>\n",
       "      <td>shoppers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.044190</td>\n",
       "      <td>currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.043436</td>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.039760</td>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.039717</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.039383</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.037978</td>\n",
       "      <td>retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.036235</td>\n",
       "      <td>chain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.035999</td>\n",
       "      <td>giant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.034112</td>\n",
       "      <td>locations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.032969</td>\n",
       "      <td>offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.032573</td>\n",
       "      <td>index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.010498</td>\n",
       "      <td>sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.010446</td>\n",
       "      <td>still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.010433</td>\n",
       "      <td>needs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.010429</td>\n",
       "      <td>request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.010369</td>\n",
       "      <td>voice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0.010339</td>\n",
       "      <td>maker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.010336</td>\n",
       "      <td>bonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>0.010320</td>\n",
       "      <td>nike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.010317</td>\n",
       "      <td>faster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.010248</td>\n",
       "      <td>postal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.010152</td>\n",
       "      <td>become</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.010149</td>\n",
       "      <td>talks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.010108</td>\n",
       "      <td>weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.010085</td>\n",
       "      <td>works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.009993</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>0.009878</td>\n",
       "      <td>steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.009757</td>\n",
       "      <td>pharmacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009752</td>\n",
       "      <td>content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.009732</td>\n",
       "      <td>losses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.009686</td>\n",
       "      <td>away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.009612</td>\n",
       "      <td>following</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.009542</td>\n",
       "      <td>expand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.009533</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.009493</td>\n",
       "      <td>department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.009473</td>\n",
       "      <td>south</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>0.009463</td>\n",
       "      <td>albertsons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0.009443</td>\n",
       "      <td>estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.009440</td>\n",
       "      <td>launched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.009434</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.009406</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MI_Values target_group\n",
       "8     0.159686       target\n",
       "13    0.077075       stores\n",
       "44    0.076992    inflation\n",
       "28    0.073780        store\n",
       "171   0.073689        child\n",
       "26    0.073004         bank\n",
       "37    0.071416     retailer\n",
       "92    0.066799      central\n",
       "389   0.064056     monetary\n",
       "15    0.059455       online\n",
       "39    0.054429    retailers\n",
       "48    0.054317     commerce\n",
       "112   0.053864        rates\n",
       "68    0.050378       policy\n",
       "83    0.047525      grocery\n",
       "85    0.045601   government\n",
       "129   0.045039     interest\n",
       "4     0.044477      company\n",
       "76    0.044253     shoppers\n",
       "402   0.044190     currency\n",
       "125   0.043436        trade\n",
       "61    0.039760         rate\n",
       "122   0.039717     shopping\n",
       "193   0.039383     economic\n",
       "29    0.037978       retail\n",
       "114   0.036235        chain\n",
       "142   0.035999        giant\n",
       "288   0.034112    locations\n",
       "203   0.032969        offer\n",
       "6     0.032573        index\n",
       "..         ...          ...\n",
       "295   0.010498         sold\n",
       "42    0.010446        still\n",
       "498   0.010433        needs\n",
       "971   0.010429      request\n",
       "342   0.010369        voice\n",
       "679   0.010339        maker\n",
       "639   0.010336        bonds\n",
       "786   0.010320         nike\n",
       "678   0.010317       faster\n",
       "981   0.010248       postal\n",
       "179   0.010152       become\n",
       "526   0.010149        talks\n",
       "996   0.010108         weak\n",
       "958   0.010085        works\n",
       "324   0.009993     internet\n",
       "954   0.009878        steps\n",
       "372   0.009757     pharmacy\n",
       "2     0.009752      content\n",
       "999   0.009732       losses\n",
       "348   0.009686         away\n",
       "329   0.009612    following\n",
       "442   0.009542       expand\n",
       "57    0.009533       health\n",
       "206   0.009493   department\n",
       "444   0.009473        south\n",
       "854   0.009463   albertsons\n",
       "773   0.009443       estate\n",
       "580   0.009440     launched\n",
       "468   0.009434       europe\n",
       "143   0.009406         want\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
