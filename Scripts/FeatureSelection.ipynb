{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get features (stops words removed) by tokenizing corpus - no stemming in baseline\n",
    "#Binary encoding\n",
    "#Assign target group \n",
    "#Use mutual information to get final feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import datasets\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Testing Feature Selection\n",
    "import nltk\n",
    "\n",
    "## Download Resources\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "from nltk.stem import *\n",
    "\n",
    "# download required resources\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# we'll compare two stemmers and a lemmatizer\n",
    "lrStem = LancasterStemmer()\n",
    "sbStem = SnowballStemmer(\"english\")\n",
    "prStem = PorterStemmer()\n",
    "wnLemm = WordNetLemmatizer()\n",
    "def wnLemm_v(word):\n",
    "    wnLemm = WordNetLemmatizer()\n",
    "    word = wnLemm.lemmatize(word, 'v')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData():\n",
    "    #Import Labelled Data\n",
    "    DATA_DIR = \"Data\"\n",
    "    thispath = Path().absolute()\n",
    "    #dtype = {\"index\": str, \"title\": str, \"description\": str, \"url\": str, \"date\": str, \"Retail Relevance\": str, \"Economy Relevant\": str, \"Market moving\": str}\n",
    "    RET_ARTICLES = os.path.join(DATA_DIR, \"Labelled_Articles_.xlsx\")\n",
    "    \n",
    "    df = pd.read_excel(RET_ARTICLES)\n",
    "\n",
    "    try:\n",
    "        df.head()\n",
    "    except:\n",
    "        pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignStopWords(): \n",
    "    #Stop_words list Options\n",
    "    #Variation 1: added stop words starting at 'one'\n",
    "    stop_words = stopwords = [\n",
    "        # dates/times\n",
    "        \"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"october\", \"november\", \"december\", \"jan\", \"feb\",\"mar\", \"apr\", \"jun\", \"jul\", \"aug\", \"oct\", \"nov\", \"dec\", \"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\", \"morning\", \"evening\",\n",
    "        # symbols that don't separate a sentence\n",
    "        '$','“','”','’','—',\n",
    "        # specific article terms that are useless\n",
    "        \"read\", \"share\", \"file\", \"'s\",\"i\", \"photo\", \"percent\",\"s\", \"t\", \"inc.\", \"corp\", \"group\", \"inc\", \"corp.\", \"source\", \"bloomberg\", \"cnbc\",\"cnbcs\", \"cnn\", \"reuters\",\"bbc\", \"published\", \"broadcast\",\"york\",\"msnbc\",\n",
    "        # other useless terms\n",
    "        \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"co\", \"inc\", \"com\", \"theyve\", \"theyre\", \"theres\", \"heres\", \"didnt\", \"wouldn\", \"couldn\", \"didn\",\"nbcuniversal\",\"according\", \"just\", \"us\", \"ll\", \"times\"#,\n",
    "        # etc\n",
    "        \"from\",\"the\", \"a\", \"with\", \"have\", \"has\", \"had\", \"having\", \"hello\", \"welcome\", \"yeah\", \"wasn\", \"today\", \"etc\", \"ext\",\"definitely\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"while\", \"of\", \"said\", \"by\", \"for\", \"about\", \"into\", \"through\", \"during\", \"before\", \"after\", \"to\", \"from\", \"in\", \"out\", \"with\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"just\", \"don\", \"now\", \"will\"\n",
    "        ]\n",
    "    #from nltk.corpus import stopwords\n",
    "    #stop_words = set(stopwords.words('english'))\n",
    "    #print(stop_words)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_count_words(df, stop_words, text_col = 'content', normalizer=None):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_counter = Counter()\n",
    "    for row in df.itertuples(index=True, name='Pandas'):\n",
    "            attribute = str((row, text_col))\n",
    "            file_words = tokenizer.tokenize(attribute)\n",
    "            #keep lowercased words that are not stop words as features\n",
    "            file_wordsNS = [word.lower() for word in file_words if not word.lower() in stop_words]\n",
    "            # remove words that are numbers\n",
    "            file_wordsN = [word for word in file_wordsNS if not word.isnumeric()]\n",
    "            #remove words with a word length less than 4 (i.e. 1-3)\n",
    "            file_wordsF = [word for word in file_wordsN if not len(word)<4]\n",
    "            \n",
    "            #stem\n",
    "            if normalizer:\n",
    "                file_wordsF = [normalizer(word) for word in file_wordsF]\n",
    "            \n",
    "            word_counter.update(file_wordsF)\n",
    "    return word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_cnt = corpus_count_words(df1,stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_cnt.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary encoding for features, also appends retail target group\n",
    "def binary_encode_features(newsarticles, top_words, text_col = 'content', normalizer=None):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    df_rows = []\n",
    "    for row in tqdm(newsarticles.itertuples(index=True, name='Pandas')):\n",
    "            attribute = str((row, text_col))\n",
    "            file_words = tokenizer.tokenize(attribute)\n",
    "            if normalizer:\n",
    "                file_words = [normalizer(word) for word in file_words]\n",
    "            df_rows.append([1 if word.lower() in file_words else 0 for word in top_words])      \n",
    "    X = pd.DataFrame(df_rows, columns = top_words)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutualInformation(B_Encoding, y, top_words): \n",
    "    #Estimate mutual information for a discrete target variable.\n",
    "    #Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables.\n",
    "    #It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "    featureVals= mutual_info_classif(B_Encoding, y, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)\n",
    "    \n",
    "    np.asarray(featureVals)\n",
    "\n",
    "    Temp= pd.DataFrame(featureVals, columns = ['MI_Values'])\n",
    " \n",
    "    Final = Temp.assign(target_group = top_words)\n",
    "    \n",
    "    Highest_Features = Final.nlargest(10000, 'MI_Values')\n",
    "    \n",
    "    return Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectFeatures(text_col = 'content', **kwargs):\n",
    "    df = importData()\n",
    "    stop_words = assignStopWords()\n",
    "    \n",
    "    if ('norm' in kwargs):\n",
    "        norm = kwargs['norm']\n",
    "        normalizers = {'lrStem' : lrStem.stem,\n",
    "                       'sbStem' : sbStem.stem,\n",
    "                       'prStem' : prStem.stem,\n",
    "                       'wnLemm' : wnLemm.lemmatize,\n",
    "                       'wnLemm-v':wnLemm_v,\n",
    "                       'baseline':None\n",
    "                      }\n",
    "        normalizer = normalizers[norm]\n",
    "    \n",
    "    #Select subset of orig data\n",
    "    #print(df.head(2))\n",
    "    df1 = df[[text_col,'market_moving']]    \n",
    "    news_cnt = corpus_count_words(df1, stop_words, text_col = text_col, normalizer = normalizer)\n",
    "    \n",
    "    print(\"starting Binary Encoding\")\n",
    "    num_features = 1000\n",
    "    top_words = [word for (word, freq) in news_cnt.most_common(num_features)]\n",
    "    B_Encoding = binary_encode_features(df1, top_words, text_col = text_col, normalizer = normalizer)\n",
    "    print(B_Encoding.head())\n",
    "    y = df['market_moving']\n",
    "    B_Encoding.assign(target_group=y)\n",
    "      \n",
    "    print(\"Finished Bin Encoding. Collecting Highest Features\")\n",
    "    Highest_Features = mutualInformation(B_Encoding, y, top_words)\n",
    "    Highest_Features = pd.DataFrame(Highest_Features)\n",
    "    \n",
    "    # Save as csv file in DATACOLLECTION data folder (bc it's needed for encoding script)\n",
    "    if ('csv' in kwargs) and (kwargs['csv']):\n",
    "        \n",
    "        # File path for this file\n",
    "        file_name = norm + text_col + 'FeatureSet.csv'\n",
    "        thispath = Path().absolute()\n",
    "        OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "        \n",
    "        # if the following line throws an error, use the line after to save in same folder\n",
    "        pd.DataFrame.to_csv(Highest_Features, path_or_buf=OUTPUT_DIR)\n",
    "        #pd.DataFrame.to_csv(Highest_Features, path_or_buf=file_name)\n",
    "    \n",
    "    print(Highest_Features)\n",
    "    return Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    HF = selectFeatures(csv = True, )\n",
    "    return HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: wnLemm\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3330it [00:03, 1031.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   title  index  panda  market_moving  amazon  stock  tech  market  apple  \\\n",
      "0      1      0      0              1       0      0     0       0      0   \n",
      "1      1      0      0              1       0      0     0       0      0   \n",
      "2      1      0      0              1       0      0     0       0      0   \n",
      "3      1      0      0              1       0      0     0       0      0   \n",
      "4      1      0      0              1       0      0     0       0      0   \n",
      "\n",
      "   wall  ...    battery  coin  regret  weak  blockbuster  roll  beer  korea  \\\n",
      "0     0  ...          0     0       0     0            0     0     0      0   \n",
      "1     0  ...          0     0       0     0            0     0     0      0   \n",
      "2     0  ...          0     0       0     0            0     0     0      0   \n",
      "3     0  ...          0     0       0     0            0     0     0      0   \n",
      "4     0  ...          0     0       0     0            0     0     0      0   \n",
      "\n",
      "   drink  crude  \n",
      "0      0      0  \n",
      "1      0      0  \n",
      "2      0      0  \n",
      "3      0      0  \n",
      "4      0      0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "     MI_Values target_group\n",
      "51    0.018731    microsoft\n",
      "814   0.017555         site\n",
      "954   0.015950  traditional\n",
      "675   0.015332      samsung\n",
      "700   0.014910        built\n",
      "370   0.014658      country\n",
      "539   0.014589    expansion\n",
      "348   0.014313       taking\n",
      "623   0.014171        sachs\n",
      "402   0.014131       double\n",
      "817   0.014081         tree\n",
      "486   0.014056     employer\n",
      "356   0.013656        owner\n",
      "722   0.013530         fire\n",
      "691   0.013323   california\n",
      "963   0.013290       pledge\n",
      "343   0.013235          add\n",
      "637   0.012926         dell\n",
      "731   0.012783      lending\n",
      "392   0.012580       budget\n",
      "747   0.012574          top\n",
      "289   0.012222    investing\n",
      "436   0.012188      shopper\n",
      "316   0.012142        small\n",
      "755   0.011916         pain\n",
      "252   0.011859        warns\n",
      "908   0.011826         ring\n",
      "386   0.011765         list\n",
      "794   0.011596     computer\n",
      "770   0.011370         soar\n",
      "..         ...          ...\n",
      "496   0.000000      housing\n",
      "498   0.000000         used\n",
      "501   0.000000      deliver\n",
      "502   0.000000         echo\n",
      "504   0.000000       expert\n",
      "505   0.000000  acquisition\n",
      "508   0.000000        hotel\n",
      "510   0.000000    continues\n",
      "476   0.000000    antitrust\n",
      "473   0.000000        early\n",
      "472   0.000000        brace\n",
      "471   0.000000         ride\n",
      "445   0.000000        worst\n",
      "446   0.000000        reach\n",
      "447   0.000000       trader\n",
      "448   0.000000   volatility\n",
      "449   0.000000     congress\n",
      "451   0.000000        issue\n",
      "452   0.000000        aetna\n",
      "455   0.000000     shipping\n",
      "458   0.000000       script\n",
      "461   0.000000         fang\n",
      "462   0.000000      payment\n",
      "464   0.000000     softbank\n",
      "465   0.000000       nearly\n",
      "466   0.000000         rest\n",
      "467   0.000000    christmas\n",
      "468   0.000000      russian\n",
      "469   0.000000        bring\n",
      "500   0.000000       hiring\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "content: wnLemm\n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3330it [00:54, 61.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   company  year  content  market  amazon  would  business  like  index  \\\n",
      "0        1     1        1       0       0      1         1     1      0   \n",
      "1        0     1        1       1       0      1         0     0      0   \n",
      "2        1     1        1       0       0      1         1     0      0   \n",
      "3        1     1        1       0       1      1         0     1      0   \n",
      "4        1     0        1       0       1      1         1     0      0   \n",
      "\n",
      "   people  ...    combined  pace  skill  supplier  echo  couple  leaving  \\\n",
      "0       1  ...           0     0      0         0     0       0        0   \n",
      "1       1  ...           0     0      0         0     0       0        0   \n",
      "2       1  ...           0     0      0         0     0       0        0   \n",
      "3       1  ...           0     0      0         0     0       0        0   \n",
      "4       1  ...           0     0      0         0     0       0        0   \n",
      "\n",
      "   developer  continues  movie  \n",
      "0          1          0      0  \n",
      "1          0          0      0  \n",
      "2          0          0      0  \n",
      "3          0          0      0  \n",
      "4          0          0      0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n",
      "     MI_Values  target_group\n",
      "150   0.038393        retail\n",
      "99    0.037898      retailer\n",
      "23    0.029910          sale\n",
      "39    0.025760         store\n",
      "225   0.021959      commerce\n",
      "310   0.021517          rule\n",
      "143   0.021237         among\n",
      "93    0.020861       quarter\n",
      "478   0.019917       shopper\n",
      "611   0.017190         japan\n",
      "263   0.016869         chain\n",
      "737   0.016089       century\n",
      "585   0.016047    regulation\n",
      "406   0.015842        agency\n",
      "392   0.015831   acquisition\n",
      "594   0.015804          size\n",
      "754   0.015674        larger\n",
      "700   0.015524          shop\n",
      "117   0.015413       walmart\n",
      "212   0.015268      delivery\n",
      "172   0.014886         every\n",
      "55    0.014779      customer\n",
      "70    0.014632          plan\n",
      "36    0.014574          much\n",
      "402   0.014521        within\n",
      "72    0.014512     financial\n",
      "778   0.014356     computing\n",
      "513   0.014178       twitter\n",
      "231   0.014150         often\n",
      "568   0.014147          live\n",
      "..         ...           ...\n",
      "75    0.000000          rate\n",
      "74    0.000000          home\n",
      "550   0.000000        player\n",
      "551   0.000000    california\n",
      "553   0.000000          john\n",
      "501   0.000000    everything\n",
      "555   0.000000         spend\n",
      "556   0.000000         class\n",
      "557   0.000000         below\n",
      "558   0.000000          vice\n",
      "560   0.000000          huge\n",
      "562   0.000000         built\n",
      "542   0.000000        united\n",
      "541   0.000000         bring\n",
      "537   0.000000          done\n",
      "76    0.000000          long\n",
      "531   0.000000  increasingly\n",
      "528   0.000000         smart\n",
      "527   0.000000      probably\n",
      "525   0.000000     economist\n",
      "77    0.000000          come\n",
      "523   0.000000    especially\n",
      "78    0.000000         money\n",
      "512   0.000000       website\n",
      "511   0.000000     insurance\n",
      "508   0.000000          wage\n",
      "507   0.000000         human\n",
      "505   0.000000        single\n",
      "504   0.000000  intelligence\n",
      "571   0.000000         taken\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "nrms = ['wnLemm-v', 'lrStem', 'sbStem', 'prStem', 'wnLemm']\n",
    "txtcols = ['title', 'content']\n",
    "\n",
    "for txtcol in txtcols:\n",
    "    #for nrm in nrms:\n",
    "    nrm = nrms[4]\n",
    "    print(txtcol + ': ' + nrm)\n",
    "    HF = selectFeatures(text_col = txtcol, norm = nrm, csv=True, )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id                                              title  \\\n",
      "0           6  Mr. Cook, Bring Back Apple's Most Important Fi...   \n",
      "1          12  These people move fast: Wealthy families are s...   \n",
      "2          18  Are GE Investors Still Tipsy on New Year's Cha...   \n",
      "3          24  What Canada can teach the US about immigration...   \n",
      "4          30          D.E. Shaw Builds Activist Stake in Lowe's   \n",
      "\n",
      "                                         description  \\\n",
      "0  The company used to say how many iPhone custom...   \n",
      "1  Wealthy families are speedy dealmakers, and th...   \n",
      "2      They seem to have gotten ahead of themselves.   \n",
      "3  Congress should look at Canada for ideas about...   \n",
      "4  Investor D.E. Shaw & Co. has built an active s...   \n",
      "\n",
      "                                                 url                date  \\\n",
      "0  https://www.bloomberg.com/gadfly/articles/2018... 2018-01-11 14:57:45   \n",
      "1  https://www.bloomberg.com/professional/blog/pe... 2018-01-11 22:04:44   \n",
      "2  https://www.bloomberg.com/gadfly/articles/2018... 2018-01-12 13:00:12   \n",
      "3  https://www.cnbc.com/2018/01/12/on-immigration... 2018-01-12 16:11:00   \n",
      "4  https://www.bloomberg.com/news/articles/2018-0... 2018-01-12 19:50:07   \n",
      "\n",
      "                                             content  Classify  market_moving  \n",
      "0  Permit me to nerd out on an essential baromete...         1              0  \n",
      "1  Theres a network thats growing of the big fami...         1              0  \n",
      "2  Beware of false starts at General Electric Co ...         1              0  \n",
      "3  Raising and educating children is expensive Th...         1              0  \n",
      "4  Investor DE Shaw amp Co has built an active st...         1              0  \n",
      "starting Binary Encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3148it [04:01, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   compani  year  content  amazon  market  like  would  also  busi  index  \\\n",
      "0        0     1        1       0       0     0      1     1     0      0   \n",
      "1        0     1        1       0       0     1      1     1     0      0   \n",
      "2        0     1        1       0       0     0      1     0     0      0   \n",
      "3        0     1        1       0       0     1      1     1     0      0   \n",
      "4        0     0        1       0       0     0      0     0     0      0   \n",
      "\n",
      "     ...     cage  onlook  kim  depositor  barb  techcrunch  vein  overreach  \\\n",
      "0    ...        0       0    0          0     0           0     0          0   \n",
      "1    ...        0       0    0          0     0           0     0          0   \n",
      "2    ...        0       0    0          0     0           0     0          0   \n",
      "3    ...        0       0    0          0     0           0     0          0   \n",
      "4    ...        0       0    0          0     0           0     0          0   \n",
      "\n",
      "   multist  sclerosi  \n",
      "0        0         0  \n",
      "1        0         0  \n",
      "2        0         0  \n",
      "3        0         0  \n",
      "4        0         0  \n",
      "\n",
      "[5 rows x 10000 columns]\n",
      "Finished Bin Encoding. Collecting Highest Features\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\Padmanie\\\\Documents\\\\GitHub\\\\Capstone\\\\DataCollection\\\\Scripts\\\\Data\\\\lr-stem-test-retailFeatureSet-MI.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-cb9946b92fd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mHighest_Features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Let Paddy know the code is done:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwinsound\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m  \u001b[1;31m# millisecond\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-315ea39e4a3e>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mHF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselectFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mHF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-473163fde97a>\u001b[0m in \u001b[0;36mselectFeatures\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# if the following line throws an error, use the line after to save in same folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHighest_Features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;31m#pd.DataFrame.to_csv(Highest_Features, path_or_buf=file_name)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    155\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\Padmanie\\\\Documents\\\\GitHub\\\\Capstone\\\\DataCollection\\\\Scripts\\\\Data\\\\lr-stem-test-retailFeatureSet-MI.csv'"
     ]
    }
   ],
   "source": [
    "Highest_Features = main()\n",
    "\n",
    "# Let Paddy know the code is done:\n",
    "import winsound\n",
    "duration = 1000  # millisecond\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)\n",
    "winsound.Beep(600, 500)\n",
    "winsound.Beep(freq, duration)\n",
    "winsound.Beep(600, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # millisecond\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)\n",
    "winsound.Beep(600, 500)\n",
    "winsound.Beep(freq, duration)\n",
    "winsound.Beep(600, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet = pd.DataFrame(Highest_Features['target_group'])\n",
    "    \n",
    "# Save as csv file in DATACOLLECTION data folder (bc it's needed for encoding script)\n",
    "\n",
    "\n",
    "# File path for this file\n",
    "file_name = 'retailFeatureSet.csv'\n",
    "thispath = Path().absolute()\n",
    "OUTPUT_DIR = os.path.join(thispath, \"Data\", file_name)\n",
    "\n",
    "# if the following line throws an error, use the line after to save in same folder\n",
    "pd.DataFrame.to_csv(featureSet, path_or_buf=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Highest_Features['MI_Values'].values)\n",
    "plt.ylabel('MI Score')\n",
    "plt.axis([0, 250, 0, 0.16])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15685016, 0.08263148, 0.08260702, 0.07286888, 0.0727404 ,\n",
       "       0.0654984 , 0.06318497, 0.05706316, 0.05342845, 0.05229887,\n",
       "       0.04736192, 0.04527032, 0.03910597, 0.0382909 , 0.03785268,\n",
       "       0.03732769, 0.03720455, 0.03714783, 0.0370412 , 0.03674766,\n",
       "       0.03660287, 0.0365798 , 0.03439267, 0.03418774, 0.03344898,\n",
       "       0.0327996 , 0.03204193, 0.03201651, 0.03143229, 0.0311371 ,\n",
       "       0.03046653, 0.02992761, 0.02967316, 0.02956049, 0.02928386,\n",
       "       0.02852677, 0.0283682 , 0.02813763, 0.02805806, 0.02797806,\n",
       "       0.0274677 , 0.02681647, 0.02657687, 0.02647535, 0.02632202,\n",
       "       0.02631743, 0.02626254, 0.02589552, 0.02561664, 0.02521897,\n",
       "       0.02488037, 0.02471711, 0.02451793, 0.0243018 , 0.02428727,\n",
       "       0.02358891, 0.02354837, 0.02335415, 0.02304278, 0.0228199 ,\n",
       "       0.02278789, 0.02273341, 0.02271051, 0.02265611, 0.0225839 ,\n",
       "       0.02241316, 0.02238736, 0.02237391, 0.02223753, 0.02202336,\n",
       "       0.02195768, 0.02182063, 0.02170697, 0.02108735, 0.02104781,\n",
       "       0.02101601, 0.0206972 , 0.02022249, 0.02014468, 0.02009752,\n",
       "       0.02003192, 0.02002081, 0.01992059, 0.01953753, 0.01944085,\n",
       "       0.01932953, 0.01925128, 0.01921858, 0.019177  , 0.01912073,\n",
       "       0.01878469, 0.01876031, 0.01819669, 0.01800605, 0.01788864,\n",
       "       0.01781546, 0.01769696, 0.01766886, 0.01748472, 0.01745597,\n",
       "       0.01719029, 0.0171628 , 0.01707625, 0.01687403, 0.01678298,\n",
       "       0.01665261, 0.01659525, 0.01657155, 0.01654005, 0.0162773 ,\n",
       "       0.01623894, 0.01621432, 0.01614828, 0.01606001, 0.01601459,\n",
       "       0.01575246, 0.01573945, 0.0155525 , 0.01543243, 0.01542022,\n",
       "       0.01526572, 0.0152326 , 0.0151825 , 0.01513105, 0.01506344,\n",
       "       0.0149539 , 0.01493832, 0.01484681, 0.01483643, 0.01483036,\n",
       "       0.01482964, 0.01482309, 0.01467814, 0.01467538, 0.01423805,\n",
       "       0.01423566, 0.01422611, 0.0141962 , 0.01415151, 0.01413871,\n",
       "       0.01409401, 0.01404255, 0.01401697, 0.01398029, 0.01395775,\n",
       "       0.01395582, 0.01380354, 0.01368303, 0.01361411, 0.01346405,\n",
       "       0.01345424, 0.01341171, 0.01336537, 0.01329642, 0.01328845,\n",
       "       0.013248  , 0.01316324, 0.01312931, 0.01309673, 0.01307972,\n",
       "       0.01304401, 0.01300114, 0.01297728, 0.01294217, 0.01293249,\n",
       "       0.01292157, 0.01277577, 0.01261388, 0.01255833, 0.01254013,\n",
       "       0.01252586, 0.01242572, 0.0124206 , 0.01240847, 0.01239289,\n",
       "       0.01238173, 0.0123756 , 0.0123511 , 0.01221895, 0.01221107,\n",
       "       0.01220684, 0.01210398, 0.01208601, 0.01207174, 0.01204127,\n",
       "       0.01190933, 0.01189506, 0.01182776, 0.01175428, 0.0117343 ,\n",
       "       0.01170031, 0.01169628, 0.01168227, 0.01166558, 0.01163642,\n",
       "       0.01161614, 0.01158428, 0.01153784, 0.01143798, 0.01142473,\n",
       "       0.01141251, 0.01137744, 0.01136863, 0.01135992, 0.01128695,\n",
       "       0.01122754, 0.011183  , 0.0111815 , 0.01110504, 0.01104444,\n",
       "       0.01101577, 0.01101385, 0.01094865, 0.01088758, 0.01088383,\n",
       "       0.01086328, 0.01084084, 0.01080057, 0.01077004, 0.01076268,\n",
       "       0.01054403, 0.01047498, 0.0103773 , 0.01036865, 0.01030642,\n",
       "       0.01027068, 0.01024832, 0.01024157, 0.01018221, 0.01017854,\n",
       "       0.01015532, 0.01009939, 0.01008728, 0.01008393, 0.01007949,\n",
       "       0.01001573, 0.00997922, 0.0099745 , 0.00996542, 0.00994597,\n",
       "       0.00993376, 0.00992274, 0.00990525, 0.00982821, 0.00980088,\n",
       "       0.00976811, 0.00973395, 0.00972009, 0.00971938, 0.00969105])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Highest_Features['MI_Values'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_Values</th>\n",
       "      <th>target_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.159686</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.077075</td>\n",
       "      <td>stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.076992</td>\n",
       "      <td>inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.073780</td>\n",
       "      <td>store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.073689</td>\n",
       "      <td>child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.073004</td>\n",
       "      <td>bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.071416</td>\n",
       "      <td>retailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.066799</td>\n",
       "      <td>central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.064056</td>\n",
       "      <td>monetary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.059455</td>\n",
       "      <td>online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.054429</td>\n",
       "      <td>retailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.054317</td>\n",
       "      <td>commerce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.053864</td>\n",
       "      <td>rates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.050378</td>\n",
       "      <td>policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.047525</td>\n",
       "      <td>grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.045601</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.045039</td>\n",
       "      <td>interest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044477</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.044253</td>\n",
       "      <td>shoppers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.044190</td>\n",
       "      <td>currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.043436</td>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.039760</td>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.039717</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.039383</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.037978</td>\n",
       "      <td>retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.036235</td>\n",
       "      <td>chain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.035999</td>\n",
       "      <td>giant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.034112</td>\n",
       "      <td>locations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.032969</td>\n",
       "      <td>offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.032573</td>\n",
       "      <td>index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.010498</td>\n",
       "      <td>sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.010446</td>\n",
       "      <td>still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.010433</td>\n",
       "      <td>needs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.010429</td>\n",
       "      <td>request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.010369</td>\n",
       "      <td>voice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0.010339</td>\n",
       "      <td>maker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.010336</td>\n",
       "      <td>bonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>0.010320</td>\n",
       "      <td>nike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.010317</td>\n",
       "      <td>faster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.010248</td>\n",
       "      <td>postal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.010152</td>\n",
       "      <td>become</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.010149</td>\n",
       "      <td>talks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.010108</td>\n",
       "      <td>weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.010085</td>\n",
       "      <td>works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.009993</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>0.009878</td>\n",
       "      <td>steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.009757</td>\n",
       "      <td>pharmacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009752</td>\n",
       "      <td>content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.009732</td>\n",
       "      <td>losses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.009686</td>\n",
       "      <td>away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.009612</td>\n",
       "      <td>following</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.009542</td>\n",
       "      <td>expand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.009533</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.009493</td>\n",
       "      <td>department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.009473</td>\n",
       "      <td>south</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>0.009463</td>\n",
       "      <td>albertsons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0.009443</td>\n",
       "      <td>estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.009440</td>\n",
       "      <td>launched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.009434</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.009406</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MI_Values target_group\n",
       "8     0.159686       target\n",
       "13    0.077075       stores\n",
       "44    0.076992    inflation\n",
       "28    0.073780        store\n",
       "171   0.073689        child\n",
       "26    0.073004         bank\n",
       "37    0.071416     retailer\n",
       "92    0.066799      central\n",
       "389   0.064056     monetary\n",
       "15    0.059455       online\n",
       "39    0.054429    retailers\n",
       "48    0.054317     commerce\n",
       "112   0.053864        rates\n",
       "68    0.050378       policy\n",
       "83    0.047525      grocery\n",
       "85    0.045601   government\n",
       "129   0.045039     interest\n",
       "4     0.044477      company\n",
       "76    0.044253     shoppers\n",
       "402   0.044190     currency\n",
       "125   0.043436        trade\n",
       "61    0.039760         rate\n",
       "122   0.039717     shopping\n",
       "193   0.039383     economic\n",
       "29    0.037978       retail\n",
       "114   0.036235        chain\n",
       "142   0.035999        giant\n",
       "288   0.034112    locations\n",
       "203   0.032969        offer\n",
       "6     0.032573        index\n",
       "..         ...          ...\n",
       "295   0.010498         sold\n",
       "42    0.010446        still\n",
       "498   0.010433        needs\n",
       "971   0.010429      request\n",
       "342   0.010369        voice\n",
       "679   0.010339        maker\n",
       "639   0.010336        bonds\n",
       "786   0.010320         nike\n",
       "678   0.010317       faster\n",
       "981   0.010248       postal\n",
       "179   0.010152       become\n",
       "526   0.010149        talks\n",
       "996   0.010108         weak\n",
       "958   0.010085        works\n",
       "324   0.009993     internet\n",
       "954   0.009878        steps\n",
       "372   0.009757     pharmacy\n",
       "2     0.009752      content\n",
       "999   0.009732       losses\n",
       "348   0.009686         away\n",
       "329   0.009612    following\n",
       "442   0.009542       expand\n",
       "57    0.009533       health\n",
       "206   0.009493   department\n",
       "444   0.009473        south\n",
       "854   0.009463   albertsons\n",
       "773   0.009443       estate\n",
       "580   0.009440     launched\n",
       "468   0.009434       europe\n",
       "143   0.009406         want\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Highest_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
