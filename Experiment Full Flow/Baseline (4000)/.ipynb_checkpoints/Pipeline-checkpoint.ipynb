{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to run all files\n",
    "* ~~All scripts currently output Excel files because we were working independently~~\n",
    "* ~~<b>We'll be changing this so that each script passes dataframes until the end of the pipeline.</b>~~\n",
    "* Our plan is to not store anything (refresh daily) but need to consider how to deal with taking in user feedback\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering articles on (Gap Inc) OR (Foot Locker) OR (L Brands) OR Macerich OR Kimco OR TJX OR CVS OR (Home Depot) OR (Best Buy) OR (Lowe's) OR Walmart OR (Target's) OR TGT OR Amazon OR Kroger OR Walgreens OR Kohl's OR (Dollar General) OR (Bed Bath and Beyond) OR Safeway from: 2019-02-25 to 2019-03-01\n",
      "997\n"
     ]
    }
   ],
   "source": [
    "#Gather Articles\n",
    "import NewsAPI as news\n",
    "import os\n",
    "\n",
    "#delete any old sorted article files\n",
    "#if os.path.exists(\"articles.csv\"):\n",
    "#    os.remove(\"articles.csv\")\n",
    "\n",
    "#inputs in order: set manual date (yes=1/no=0, no = last 24 hours of news), manual start date as \"YYYY-MM-DD\"(leave empty if 0), manual end date (leave empty if 0, companies to pull (6= all 19 companies)\n",
    "articleDB = news.main(1,\"2019-02-25\",\"2019-03-01\",6) #output is called 'NewsAPIOutput.xlsx' in Python Scripts > Data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Article Cleaning (must pip install tqdm first (only once) to run)\n",
    "import dataClean as dc\n",
    "articleDB = dc.DataClean(articleDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Feature Selection and Binary Article Encoding\n",
    "import FeatureEncoding as fe\n",
    "contentBinaryMatrix = fe.encoding(0, df=articleDB, text_col='content', norm='wnLemm')\n",
    "titleBinaryMatrix = fe.encoding(0, df=articleDB, text_col = 'title', norm='wnLemm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Classifier + Article Ranking, complete final file is called 'results_encoding.xlsx'\n",
    "import logReg as lr\n",
    "articleDB = lr.runLogReg(titleBinaryMatrix, contentBinaryMatrix, articleDB)\n",
    "#articleDB = runLogReg(titleBinaryMatrix, contentBinaryMatrix, articleDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code extracts and ranks \"tags\" + counts frequency of tag mentions in articles \n",
    "\"\"\"\n",
    "Inputs: \n",
    "    1) articleDB - uses column 'content'\n",
    "    2) (optional) - tag type (could be 'ngrams'{unlimited}, 'bigrams'{terms with up to 2 words}, or 'unigrams'{single terms})\n",
    "        - default is 'bigrams'\n",
    "        - future work: add in noun phrases, named entities \n",
    "Outputs:\n",
    "    1) articleDB = articleDB with appended columns \"tags\" and \"tags_top_5\"\n",
    "    2) trendingTermsDB = keyterms by # article mentions\n",
    "\"\"\"\n",
    "import ContextExtraction as ce\n",
    "articleDB, trendingTermsDB = ce.retrieveContext(articleDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import EncodingforRecommender as rec\n",
    "articleDB = rec.recommender(articleDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import frontPage as fp\n",
    "frontpage = fp.FrontPage(articleDB, trendingTermsDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "articles = pd.DataFrame(frontpage['articles'])\n",
    "topterms= pd.DataFrame(frontpage['topterms'])\n",
    "articles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.DataFrame(articles['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_excel(articleDB, 'Main Version-25-01.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
