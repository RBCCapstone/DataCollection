{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to run all files\n",
    "* ~~All scripts currently output Excel files because we were working independently~~\n",
    "* ~~<b>We'll be changing this so that each script passes dataframes until the end of the pipeline.</b>~~\n",
    "* Our plan is to not store anything (refresh daily) but need to consider how to deal with taking in user feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering articles on (Gap Inc) OR (Foot Locker) OR (L Brands) OR Macerich OR Kimco OR TJX OR CVS OR (Home Depot) OR (Best Buy) OR (Lowe's) OR Walmart OR (Target's) OR TGT OR Amazon OR Kroger OR Walgreens OR Kohl's OR (Dollar General) OR (Bed Bath and Beyond) OR Safeway from: 2019-03-12 to 2019-03-13\n",
      "337\n"
     ]
    }
   ],
   "source": [
    "#Gather Articles\n",
    "import NewsAPI as news\n",
    "import os\n",
    "\n",
    "#delete any old sorted article files\n",
    "#if os.path.exists(\"articles.csv\"):\n",
    "#    os.remove(\"articles.csv\")\n",
    "\n",
    "#inputs in order: set manual date (yes=1/no=0, no = last 24 hours of news), manual start date as \"YYYY-MM-DD\"(leave empty if 0), manual end date (leave empty if 0, companies to pull (6= all 19 companies)\n",
    "articleDB = news.main(1,\"2019-03-12\",\"2019-03-13\",6) #output is called 'NewsAPIOutput.xlsx' in Python Scripts > Data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Article Cleaning (must pip install tqdm first (only once) to run)\n",
    "import dataClean as dc\n",
    "articleDB = dc.DataClean(articleDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Padmanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "content\n",
      "wnLemm\n",
      "Binary Encoding\n",
      "True\n",
      "title\n",
      "wnLemm\n",
      "Binary Encoding\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection and Binary Article Encoding\n",
    "import FeatureEncoding as fe\n",
    "contentBinaryMatrix = fe.encoding(0, df=articleDB, text_col='content', norm='wnLemm')\n",
    "titleBinaryMatrix = fe.encoding(0, df=articleDB, text_col = 'title', norm='wnLemm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([0, 1, 'article_id', 'prediction'], dtype='object')\n",
      "                                               title  \\\n",
      "0            US retail sales bounced back in January   \n",
      "1  ‘It’s show time’: Apple event on March 25 expe...   \n",
      "2  Historic ‘bomb cyclone’ sets off severe storms...   \n",
      "3  UBS is now sounding the alarm on Amazon taking...   \n",
      "4  US stocks move higher, led by technology and h...   \n",
      "\n",
      "                                         description  \n",
      "0  This is an excerpt from a story delivered excl...  \n",
      "1  Apple has long hinted at the move, spending US...  \n",
      "2  The storm is setting records as it unleashes d...  \n",
      "3  Amazon is developing a third-party logistics p...  \n",
      "4  NEW YORK (AP) — U.S. stocks opened broadly hig...  \n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Classifier + Article Ranking, complete final file is called 'results_encoding.xlsx'\n",
    "import logReg as lr\n",
    "articleDB = lr.runLogReg(titleBinaryMatrix, contentBinaryMatrix, articleDB)\n",
    "#articleDB = runLogReg(titleBinaryMatrix, contentBinaryMatrix, articleDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▏                                              | 91/216 [00:01<00:01, 63.44it/s]"
     ]
    }
   ],
   "source": [
    "# This code extracts and ranks \"tags\" + counts frequency of tag mentions in articles \n",
    "\"\"\"\n",
    "Inputs: \n",
    "    1) articleDB - uses column 'content'\n",
    "    2) (optional) - tag type (could be 'ngrams'{unlimited}, 'bigrams'{terms with up to 2 words}, or 'unigrams'{single terms})\n",
    "        - default is 'bigrams'\n",
    "        - future work: add in noun phrases, named entities \n",
    "Outputs:\n",
    "    1) articleDB = articleDB with appended columns \"tags\" and \"tags_top_5\"\n",
    "    2) trendingTermsDB = keyterms by # article mentions\n",
    "\"\"\"\n",
    "import ContextExtraction as ce\n",
    "articleDB, trendingTermsDB = ce.retrieveContext(articleDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import EncodingforRecommender as rec\n",
    "articleDB = rec.recommender(articleDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import frontPage as fp\n",
    "frontpage = fp.FrontPage(articleDB, trendingTermsDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "articles = pd.DataFrame(frontpage['articles'])\n",
    "topterms= pd.DataFrame(frontpage['topterms'])\n",
    "articles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.DataFrame(articles['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_excel(articleDB, 'Main Version-original cleaner-12-13.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
